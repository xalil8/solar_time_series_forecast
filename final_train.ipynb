{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option(\"max_columns\",None)\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "#from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.activations import relu,linear\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from matplotlib import units\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,make_scorer,r2_score,mean_absolute_percentage_error\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api  as sm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, SGDRegressor,LinearRegression,RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,RobustScaler\n",
    "#from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor,DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.ExcelFile('C:/Users/halil/Desktop/soalr_data.xlsx').parse('sheet 1')\n",
    "weather_raw = pd.read_excel('C:/Users/halil/Desktop/soalr_data.xlsx',sheet_name=\"weather\")\n",
    "guneko_raw = pd.read_excel('C:/Users/halil/Desktop/soalr_data.xlsx',sheet_name=\"1000255-GUNEKO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA INITILAZING AND CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "guneko_production = guneko_raw[[\"Date\",\"Production\"]]\n",
    "guneko_gti = guneko_raw[[\"Date.1\",\"GTI\"]]\n",
    "\n",
    "\n",
    "weather_guneko = weather_raw.loc[weather_raw.name ==1000255]\n",
    "ali = pd.merge(guneko_production,weather_guneko,left_on=\"Date\",right_on=\"date\")\n",
    "dataset = ali.drop([\"name\",\"date\",\"lat\",\"lon\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ONE HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= dataset.set_index([\"Date\"])\n",
    "year = pd.DataFrame(data=pd.get_dummies(dataset.index.year,prefix=\"year\"))\n",
    "month = pd.DataFrame(data=pd.get_dummies(dataset.index.month, prefix=\"month\"))\n",
    "#day = pd.DataFrame(data=pd.get_dummies(dataset.index.day,prefix=\"day\"))\n",
    "hour = pd.DataFrame(data=pd.get_dummies(dataset.index.hour,prefix=\"hour\"))\n",
    "#frames = [year,month,day,hour]\n",
    "frames = [year,month,hour]\n",
    "onehot_encoded = ali.join(frames)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_encoded = onehot_encoded.drop([\"Date\",\"name\",\"date\",\"lat\",\"lon\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NORMALIZATION OF FEATURES (EXCEPTIONS: PRODUCTION AND DATE TIME ENCODED FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df,column_list):\n",
    "    for col in column_list:\n",
    "        feature_range = (-1,1)\n",
    "        min_max_scaler = MinMaxScaler(feature_range=feature_range)\n",
    "\n",
    "        df[col] = min_max_scaler.fit_transform(df[col].values.reshape(-1,1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Production</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cloud cover</th>\n",
       "      <th>global_rad:W</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>relative_humidity_2m:p</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>prob_precip_1h:p</th>\n",
       "      <th>t_apparent:C</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.303571</td>\n",
       "      <td>-0.346</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.884332</td>\n",
       "      <td>-0.897959</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.312407</td>\n",
       "      <td>-0.989333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.339286</td>\n",
       "      <td>-0.518</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.949527</td>\n",
       "      <td>-0.816327</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.986667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.367857</td>\n",
       "      <td>-0.650</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>-0.795918</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.366218</td>\n",
       "      <td>-0.873333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.382143</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>-0.816327</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.378176</td>\n",
       "      <td>-0.733333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.435714</td>\n",
       "      <td>0.634</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.795918</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.423019</td>\n",
       "      <td>-0.576000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19031</th>\n",
       "      <td>-0.179179</td>\n",
       "      <td>-0.203571</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.146112</td>\n",
       "      <td>0.353916</td>\n",
       "      <td>-0.353991</td>\n",
       "      <td>-0.255521</td>\n",
       "      <td>-0.244898</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.121076</td>\n",
       "      <td>0.628000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19032</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.160714</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.290626</td>\n",
       "      <td>0.440636</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>-0.312303</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.001495</td>\n",
       "      <td>0.698667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19033</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.139286</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.051969</td>\n",
       "      <td>0.512826</td>\n",
       "      <td>-0.546714</td>\n",
       "      <td>-0.303891</td>\n",
       "      <td>-0.346939</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.028401</td>\n",
       "      <td>0.705333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19034</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>0.984</td>\n",
       "      <td>-0.277833</td>\n",
       "      <td>0.330760</td>\n",
       "      <td>-0.839906</td>\n",
       "      <td>-0.284963</td>\n",
       "      <td>-0.510204</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.082212</td>\n",
       "      <td>0.646667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19035</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.157143</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-0.512493</td>\n",
       "      <td>-0.013394</td>\n",
       "      <td>-0.937559</td>\n",
       "      <td>-0.261830</td>\n",
       "      <td>-0.693878</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.118087</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19036 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Production  temperature  cloud cover  global_rad:W  diffuse_rad:W  \\\n",
       "0       -1.000000    -0.303571       -0.346     -1.000000      -1.000000   \n",
       "1       -1.000000    -0.339286       -0.518     -1.000000      -1.000000   \n",
       "2       -1.000000    -0.367857       -0.650     -1.000000      -1.000000   \n",
       "3       -1.000000    -0.382143       -0.760     -1.000000      -1.000000   \n",
       "4       -1.000000    -0.435714        0.634     -1.000000      -1.000000   \n",
       "...           ...          ...          ...           ...            ...   \n",
       "19031   -0.179179    -0.203571        0.644      0.146112       0.353916   \n",
       "19032   -1.000000    -0.160714        0.724      0.290626       0.440636   \n",
       "19033   -1.000000    -0.139286        0.930      0.051969       0.512826   \n",
       "19034   -1.000000    -0.150000        0.984     -0.277833       0.330760   \n",
       "19035   -1.000000    -0.157143        0.952     -0.512493      -0.013394   \n",
       "\n",
       "       direct_rad:W  relative_humidity_2m:p  wind_speed_10m:ms  \\\n",
       "0         -1.000000                0.884332          -0.897959   \n",
       "1         -1.000000                0.949527          -0.816327   \n",
       "2         -1.000000                0.970557          -0.795918   \n",
       "3         -1.000000                0.970557          -0.816327   \n",
       "4         -1.000000                1.000000          -0.795918   \n",
       "...             ...                     ...                ...   \n",
       "19031     -0.353991               -0.255521          -0.244898   \n",
       "19032     -0.229108               -0.312303          -0.285714   \n",
       "19033     -0.546714               -0.303891          -0.346939   \n",
       "19034     -0.839906               -0.284963          -0.510204   \n",
       "19035     -0.937559               -0.261830          -0.693878   \n",
       "\n",
       "       prob_precip_1h:p  t_apparent:C  sun_elevation:d  year_2020  year_2021  \\\n",
       "0                  -1.0     -0.312407        -0.989333          1          0   \n",
       "1                  -1.0     -0.342302        -0.986667          1          0   \n",
       "2                  -1.0     -0.366218        -0.873333          1          0   \n",
       "3                  -1.0     -0.378176        -0.733333          1          0   \n",
       "4                  -1.0     -0.423019        -0.576000          1          0   \n",
       "...                 ...           ...              ...        ...        ...   \n",
       "19031              -1.0     -0.121076         0.628000          0          0   \n",
       "19032              -1.0     -0.001495         0.698667          0          0   \n",
       "19033              -1.0     -0.028401         0.705333          0          0   \n",
       "19034              -1.0     -0.082212         0.646667          0          0   \n",
       "19035              -1.0     -0.118087         0.540000          0          0   \n",
       "\n",
       "       year_2022  month_1  month_2  month_3  month_4  month_5  month_6  \\\n",
       "0              0        1        0        0        0        0        0   \n",
       "1              0        1        0        0        0        0        0   \n",
       "2              0        1        0        0        0        0        0   \n",
       "3              0        1        0        0        0        0        0   \n",
       "4              0        1        0        0        0        0        0   \n",
       "...          ...      ...      ...      ...      ...      ...      ...   \n",
       "19031          1        0        0        1        0        0        0   \n",
       "19032          1        0        0        1        0        0        0   \n",
       "19033          1        0        0        1        0        0        0   \n",
       "19034          1        0        0        1        0        0        0   \n",
       "19035          1        0        0        1        0        0        0   \n",
       "\n",
       "       month_7  month_8  month_9  month_10  month_11  month_12  hour_0  \\\n",
       "0            0        0        0         0         0         0       1   \n",
       "1            0        0        0         0         0         0       0   \n",
       "2            0        0        0         0         0         0       0   \n",
       "3            0        0        0         0         0         0       0   \n",
       "4            0        0        0         0         0         0       0   \n",
       "...        ...      ...      ...       ...       ...       ...     ...   \n",
       "19031        0        0        0         0         0         0       0   \n",
       "19032        0        0        0         0         0         0       0   \n",
       "19033        0        0        0         0         0         0       0   \n",
       "19034        0        0        0         0         0         0       0   \n",
       "19035        0        0        0         0         0         0       0   \n",
       "\n",
       "       hour_1  hour_2  hour_3  hour_4  hour_5  hour_6  hour_7  hour_8  hour_9  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           1       0       0       0       0       0       0       0       0   \n",
       "2           0       1       0       0       0       0       0       0       0   \n",
       "3           0       0       1       0       0       0       0       0       0   \n",
       "4           0       0       0       1       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "19031       0       0       0       0       0       0       0       0       0   \n",
       "19032       0       0       0       0       0       0       0       0       0   \n",
       "19033       0       0       0       0       0       0       0       0       0   \n",
       "19034       0       0       0       0       0       0       0       0       0   \n",
       "19035       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       hour_10  hour_11  hour_12  hour_13  hour_14  hour_15  hour_16  hour_17  \\\n",
       "0            0        0        0        0        0        0        0        0   \n",
       "1            0        0        0        0        0        0        0        0   \n",
       "2            0        0        0        0        0        0        0        0   \n",
       "3            0        0        0        0        0        0        0        0   \n",
       "4            0        0        0        0        0        0        0        0   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "19031        0        1        0        0        0        0        0        0   \n",
       "19032        0        0        1        0        0        0        0        0   \n",
       "19033        0        0        0        1        0        0        0        0   \n",
       "19034        0        0        0        0        1        0        0        0   \n",
       "19035        0        0        0        0        0        1        0        0   \n",
       "\n",
       "       hour_18  hour_19  hour_20  hour_21  hour_22  hour_23  \n",
       "0            0        0        0        0        0        0  \n",
       "1            0        0        0        0        0        0  \n",
       "2            0        0        0        0        0        0  \n",
       "3            0        0        0        0        0        0  \n",
       "4            0        0        0        0        0        0  \n",
       "...        ...      ...      ...      ...      ...      ...  \n",
       "19031        0        0        0        0        0        0  \n",
       "19032        0        0        0        0        0        0  \n",
       "19033        0        0        0        0        0        0  \n",
       "19034        0        0        0        0        0        0  \n",
       "19035        0        0        0        0        0        0  \n",
       "\n",
       "[19036 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized = normalize(onehot_encoded,onehot_encoded.columns[0:11])\n",
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = normalized.loc[normalized.year_2021 == 1]\n",
    "target = target.drop([\"year_2020\",\"year_2022\",\"year_2021\"],axis=1)\n",
    "target = target.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw = normalized.loc[normalized.year_2022 == 1]\n",
    "aw1 = aw.loc[aw.month_1 ==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CHOOSİNG SPECIFIC TRAIN AND TEST DATA . I CHOOSE 1 YEAR LONG TRAIN DATA AND A WEEK OF TEST DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_year = normalized[8712:17133].reset_index(drop=True)\n",
    "test_one_week = normalized[17133:17863].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Production</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cloud cover</th>\n",
       "      <th>global_rad:W</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>relative_humidity_2m:p</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>prob_precip_1h:p</th>\n",
       "      <th>t_apparent:C</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.332143</td>\n",
       "      <td>0.240</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.482650</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.384155</td>\n",
       "      <td>-0.985333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.317857</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.421661</td>\n",
       "      <td>-0.653061</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.360239</td>\n",
       "      <td>-0.872000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.317857</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.396425</td>\n",
       "      <td>-0.612245</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.369208</td>\n",
       "      <td>-0.741333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.357143</td>\n",
       "      <td>0.542</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.581493</td>\n",
       "      <td>-0.510204</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.420030</td>\n",
       "      <td>-0.584000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.342857</td>\n",
       "      <td>0.536</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.543638</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.399103</td>\n",
       "      <td>-0.425333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8416</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.360714</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>-0.653061</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.402093</td>\n",
       "      <td>-0.252000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.346429</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.375394</td>\n",
       "      <td>-0.795918</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.348281</td>\n",
       "      <td>-0.409333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.379600</td>\n",
       "      <td>-0.816327</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.351271</td>\n",
       "      <td>-0.568000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8419</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.385714</td>\n",
       "      <td>0.388</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.524711</td>\n",
       "      <td>-0.632653</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.426009</td>\n",
       "      <td>-0.725333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8420</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.407143</td>\n",
       "      <td>0.996</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.596215</td>\n",
       "      <td>-0.632653</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.449925</td>\n",
       "      <td>-0.873333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8421 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Production  temperature  cloud cover  global_rad:W  diffuse_rad:W  \\\n",
       "0           -1.0    -0.332143        0.240          -1.0           -1.0   \n",
       "1           -1.0    -0.317857       -0.050          -1.0           -1.0   \n",
       "2           -1.0    -0.317857        0.008          -1.0           -1.0   \n",
       "3           -1.0    -0.357143        0.542          -1.0           -1.0   \n",
       "4           -1.0    -0.342857        0.536          -1.0           -1.0   \n",
       "...          ...          ...          ...           ...            ...   \n",
       "8416        -1.0    -0.360714        0.000          -1.0           -1.0   \n",
       "8417        -1.0    -0.346429        0.036          -1.0           -1.0   \n",
       "8418        -1.0    -0.350000        0.066          -1.0           -1.0   \n",
       "8419        -1.0    -0.385714        0.388          -1.0           -1.0   \n",
       "8420        -1.0    -0.407143        0.996          -1.0           -1.0   \n",
       "\n",
       "      direct_rad:W  relative_humidity_2m:p  wind_speed_10m:ms  \\\n",
       "0             -1.0                0.482650          -0.571429   \n",
       "1             -1.0                0.421661          -0.653061   \n",
       "2             -1.0                0.396425          -0.612245   \n",
       "3             -1.0                0.581493          -0.510204   \n",
       "4             -1.0                0.543638          -0.571429   \n",
       "...            ...                     ...                ...   \n",
       "8416          -1.0                0.444795          -0.653061   \n",
       "8417          -1.0                0.375394          -0.795918   \n",
       "8418          -1.0                0.379600          -0.816327   \n",
       "8419          -1.0                0.524711          -0.632653   \n",
       "8420          -1.0                0.596215          -0.632653   \n",
       "\n",
       "      prob_precip_1h:p  t_apparent:C  sun_elevation:d  year_2020  year_2021  \\\n",
       "0                 -1.0     -0.384155        -0.985333          0          1   \n",
       "1                 -1.0     -0.360239        -0.872000          0          1   \n",
       "2                 -1.0     -0.369208        -0.741333          0          1   \n",
       "3                 -1.0     -0.420030        -0.584000          0          1   \n",
       "4                 -1.0     -0.399103        -0.425333          0          1   \n",
       "...                ...           ...              ...        ...        ...   \n",
       "8416              -1.0     -0.402093        -0.252000          0          1   \n",
       "8417              -1.0     -0.348281        -0.409333          0          1   \n",
       "8418              -1.0     -0.351271        -0.568000          0          1   \n",
       "8419              -1.0     -0.426009        -0.725333          0          1   \n",
       "8420              -1.0     -0.449925        -0.873333          0          1   \n",
       "\n",
       "      year_2022  month_1  month_2  month_3  month_4  month_5  month_6  \\\n",
       "0             0        1        0        0        0        0        0   \n",
       "1             0        1        0        0        0        0        0   \n",
       "2             0        1        0        0        0        0        0   \n",
       "3             0        1        0        0        0        0        0   \n",
       "4             0        1        0        0        0        0        0   \n",
       "...         ...      ...      ...      ...      ...      ...      ...   \n",
       "8416          0        0        0        0        0        0        0   \n",
       "8417          0        0        0        0        0        0        0   \n",
       "8418          0        0        0        0        0        0        0   \n",
       "8419          0        0        0        0        0        0        0   \n",
       "8420          0        0        0        0        0        0        0   \n",
       "\n",
       "      month_7  month_8  month_9  month_10  month_11  month_12  hour_0  hour_1  \\\n",
       "0           0        0        0         0         0         0       0       1   \n",
       "1           0        0        0         0         0         0       0       0   \n",
       "2           0        0        0         0         0         0       0       0   \n",
       "3           0        0        0         0         0         0       0       0   \n",
       "4           0        0        0         0         0         0       0       0   \n",
       "...       ...      ...      ...       ...       ...       ...     ...     ...   \n",
       "8416        0        0        0         0         0         1       0       0   \n",
       "8417        0        0        0         0         0         1       0       0   \n",
       "8418        0        0        0         0         0         1       0       0   \n",
       "8419        0        0        0         0         0         1       0       0   \n",
       "8420        0        0        0         0         0         1       0       0   \n",
       "\n",
       "      hour_2  hour_3  hour_4  hour_5  hour_6  hour_7  hour_8  hour_9  hour_10  \\\n",
       "0          0       0       0       0       0       0       0       0        0   \n",
       "1          1       0       0       0       0       0       0       0        0   \n",
       "2          0       1       0       0       0       0       0       0        0   \n",
       "3          0       0       1       0       0       0       0       0        0   \n",
       "4          0       0       0       1       0       0       0       0        0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...      ...   \n",
       "8416       0       0       0       0       0       0       0       0        0   \n",
       "8417       0       0       0       0       0       0       0       0        0   \n",
       "8418       0       0       0       0       0       0       0       0        0   \n",
       "8419       0       0       0       0       0       0       0       0        0   \n",
       "8420       0       0       0       0       0       0       0       0        0   \n",
       "\n",
       "      hour_11  hour_12  hour_13  hour_14  hour_15  hour_16  hour_17  hour_18  \\\n",
       "0           0        0        0        0        0        0        0        0   \n",
       "1           0        0        0        0        0        0        0        0   \n",
       "2           0        0        0        0        0        0        0        0   \n",
       "3           0        0        0        0        0        0        0        0   \n",
       "4           0        0        0        0        0        0        0        0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "8416        0        0        0        0        0        0        0        0   \n",
       "8417        0        0        0        0        0        0        0        0   \n",
       "8418        0        0        0        0        0        0        0        0   \n",
       "8419        0        0        0        0        0        0        0        0   \n",
       "8420        0        0        0        0        0        0        0        0   \n",
       "\n",
       "      hour_19  hour_20  hour_21  hour_22  hour_23  \n",
       "0           0        0        0        0        0  \n",
       "1           0        0        0        0        0  \n",
       "2           0        0        0        0        0  \n",
       "3           0        0        0        0        0  \n",
       "4           0        0        0        0        0  \n",
       "...       ...      ...      ...      ...      ...  \n",
       "8416        1        0        0        0        0  \n",
       "8417        0        1        0        0        0  \n",
       "8418        0        0        1        0        0  \n",
       "8419        0        0        0        1        0  \n",
       "8420        0        0        0        0        1  \n",
       "\n",
       "[8421 rows x 50 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Production</th>\n",
       "      <th>temperature</th>\n",
       "      <th>cloud cover</th>\n",
       "      <th>global_rad:W</th>\n",
       "      <th>diffuse_rad:W</th>\n",
       "      <th>direct_rad:W</th>\n",
       "      <th>relative_humidity_2m:p</th>\n",
       "      <th>wind_speed_10m:ms</th>\n",
       "      <th>prob_precip_1h:p</th>\n",
       "      <th>t_apparent:C</th>\n",
       "      <th>sun_elevation:d</th>\n",
       "      <th>year_2020</th>\n",
       "      <th>year_2021</th>\n",
       "      <th>year_2022</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>hour_0</th>\n",
       "      <th>hour_1</th>\n",
       "      <th>hour_2</th>\n",
       "      <th>hour_3</th>\n",
       "      <th>hour_4</th>\n",
       "      <th>hour_5</th>\n",
       "      <th>hour_6</th>\n",
       "      <th>hour_7</th>\n",
       "      <th>hour_8</th>\n",
       "      <th>hour_9</th>\n",
       "      <th>hour_10</th>\n",
       "      <th>hour_11</th>\n",
       "      <th>hour_12</th>\n",
       "      <th>hour_13</th>\n",
       "      <th>hour_14</th>\n",
       "      <th>hour_15</th>\n",
       "      <th>hour_16</th>\n",
       "      <th>hour_17</th>\n",
       "      <th>hour_18</th>\n",
       "      <th>hour_19</th>\n",
       "      <th>hour_20</th>\n",
       "      <th>hour_21</th>\n",
       "      <th>hour_22</th>\n",
       "      <th>hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.967968</td>\n",
       "      <td>-0.342857</td>\n",
       "      <td>0.990</td>\n",
       "      <td>-0.845892</td>\n",
       "      <td>-0.664926</td>\n",
       "      <td>-0.992488</td>\n",
       "      <td>0.760252</td>\n",
       "      <td>-0.448980</td>\n",
       "      <td>-0.612766</td>\n",
       "      <td>-0.390135</td>\n",
       "      <td>0.264000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.857858</td>\n",
       "      <td>-0.314286</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.719768</td>\n",
       "      <td>-0.435187</td>\n",
       "      <td>-0.962911</td>\n",
       "      <td>0.699264</td>\n",
       "      <td>-0.469388</td>\n",
       "      <td>-0.714894</td>\n",
       "      <td>-0.339312</td>\n",
       "      <td>0.345333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.805806</td>\n",
       "      <td>-0.292857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.657805</td>\n",
       "      <td>-0.320318</td>\n",
       "      <td>-0.949296</td>\n",
       "      <td>0.659306</td>\n",
       "      <td>-0.346939</td>\n",
       "      <td>-0.802128</td>\n",
       "      <td>-0.321375</td>\n",
       "      <td>0.389333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.723724</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.669998</td>\n",
       "      <td>-0.334393</td>\n",
       "      <td>-0.956573</td>\n",
       "      <td>0.623554</td>\n",
       "      <td>-0.346939</td>\n",
       "      <td>-0.906383</td>\n",
       "      <td>-0.318386</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.647648</td>\n",
       "      <td>-0.282143</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.707376</td>\n",
       "      <td>-0.401135</td>\n",
       "      <td>-0.965962</td>\n",
       "      <td>0.585699</td>\n",
       "      <td>-0.367347</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.318386</td>\n",
       "      <td>0.350667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.785489</td>\n",
       "      <td>-0.306122</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.512706</td>\n",
       "      <td>-0.185333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.421429</td>\n",
       "      <td>0.986</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.766562</td>\n",
       "      <td>-0.448980</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.494768</td>\n",
       "      <td>-0.344000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.421429</td>\n",
       "      <td>0.886</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.758149</td>\n",
       "      <td>-0.510204</td>\n",
       "      <td>-0.814894</td>\n",
       "      <td>-0.479821</td>\n",
       "      <td>-0.502667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.425000</td>\n",
       "      <td>0.938</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.785489</td>\n",
       "      <td>-0.489796</td>\n",
       "      <td>-0.768085</td>\n",
       "      <td>-0.488789</td>\n",
       "      <td>-0.657333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.442857</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.825447</td>\n",
       "      <td>-0.448980</td>\n",
       "      <td>-0.834043</td>\n",
       "      <td>-0.512706</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>730 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Production  temperature  cloud cover  global_rad:W  diffuse_rad:W  \\\n",
       "0     -0.967968    -0.342857        0.990     -0.845892      -0.664926   \n",
       "1     -0.857858    -0.314286        1.000     -0.719768      -0.435187   \n",
       "2     -0.805806    -0.292857        1.000     -0.657805      -0.320318   \n",
       "3     -0.723724    -0.285714        1.000     -0.669998      -0.334393   \n",
       "4     -0.647648    -0.282143        1.000     -0.707376      -0.401135   \n",
       "..          ...          ...          ...           ...            ...   \n",
       "725   -1.000000    -0.425000        0.994     -1.000000      -1.000000   \n",
       "726   -1.000000    -0.421429        0.986     -1.000000      -1.000000   \n",
       "727   -1.000000    -0.421429        0.886     -1.000000      -1.000000   \n",
       "728   -1.000000    -0.425000        0.938     -1.000000      -1.000000   \n",
       "729   -1.000000    -0.442857        1.000     -1.000000      -1.000000   \n",
       "\n",
       "     direct_rad:W  relative_humidity_2m:p  wind_speed_10m:ms  \\\n",
       "0       -0.992488                0.760252          -0.448980   \n",
       "1       -0.962911                0.699264          -0.469388   \n",
       "2       -0.949296                0.659306          -0.346939   \n",
       "3       -0.956573                0.623554          -0.346939   \n",
       "4       -0.965962                0.585699          -0.367347   \n",
       "..            ...                     ...                ...   \n",
       "725     -1.000000                0.785489          -0.306122   \n",
       "726     -1.000000                0.766562          -0.448980   \n",
       "727     -1.000000                0.758149          -0.510204   \n",
       "728     -1.000000                0.785489          -0.489796   \n",
       "729     -1.000000                0.825447          -0.448980   \n",
       "\n",
       "     prob_precip_1h:p  t_apparent:C  sun_elevation:d  year_2020  year_2021  \\\n",
       "0           -0.612766     -0.390135         0.264000          0          0   \n",
       "1           -0.714894     -0.339312         0.345333          0          0   \n",
       "2           -0.802128     -0.321375         0.389333          0          0   \n",
       "3           -0.906383     -0.318386         0.392000          0          0   \n",
       "4           -1.000000     -0.318386         0.350667          0          0   \n",
       "..                ...           ...              ...        ...        ...   \n",
       "725         -1.000000     -0.512706        -0.185333          0          0   \n",
       "726         -1.000000     -0.494768        -0.344000          0          0   \n",
       "727         -0.814894     -0.479821        -0.502667          0          0   \n",
       "728         -0.768085     -0.488789        -0.657333          0          0   \n",
       "729         -0.834043     -0.512706        -0.800000          0          0   \n",
       "\n",
       "     year_2022  month_1  month_2  month_3  month_4  month_5  month_6  month_7  \\\n",
       "0            1        1        0        0        0        0        0        0   \n",
       "1            1        1        0        0        0        0        0        0   \n",
       "2            1        1        0        0        0        0        0        0   \n",
       "3            1        1        0        0        0        0        0        0   \n",
       "4            1        1        0        0        0        0        0        0   \n",
       "..         ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "725          1        1        0        0        0        0        0        0   \n",
       "726          1        1        0        0        0        0        0        0   \n",
       "727          1        1        0        0        0        0        0        0   \n",
       "728          1        1        0        0        0        0        0        0   \n",
       "729          1        1        0        0        0        0        0        0   \n",
       "\n",
       "     month_8  month_9  month_10  month_11  month_12  hour_0  hour_1  hour_2  \\\n",
       "0          0        0         0         0         0       0       0       0   \n",
       "1          0        0         0         0         0       0       0       0   \n",
       "2          0        0         0         0         0       0       0       0   \n",
       "3          0        0         0         0         0       0       0       0   \n",
       "4          0        0         0         0         0       0       0       0   \n",
       "..       ...      ...       ...       ...       ...     ...     ...     ...   \n",
       "725        0        0         0         0         0       0       0       0   \n",
       "726        0        0         0         0         0       0       0       0   \n",
       "727        0        0         0         0         0       0       0       0   \n",
       "728        0        0         0         0         0       0       0       0   \n",
       "729        0        0         0         0         0       0       0       0   \n",
       "\n",
       "     hour_3  hour_4  hour_5  hour_6  hour_7  hour_8  hour_9  hour_10  hour_11  \\\n",
       "0         0       0       0       0       0       0       0        1        0   \n",
       "1         0       0       0       0       0       0       0        0        1   \n",
       "2         0       0       0       0       0       0       0        0        0   \n",
       "3         0       0       0       0       0       0       0        0        0   \n",
       "4         0       0       0       0       0       0       0        0        0   \n",
       "..      ...     ...     ...     ...     ...     ...     ...      ...      ...   \n",
       "725       0       0       0       0       0       0       0        0        0   \n",
       "726       0       0       0       0       0       0       0        0        0   \n",
       "727       0       0       0       0       0       0       0        0        0   \n",
       "728       0       0       0       0       0       0       0        0        0   \n",
       "729       0       0       0       0       0       0       0        0        0   \n",
       "\n",
       "     hour_12  hour_13  hour_14  hour_15  hour_16  hour_17  hour_18  hour_19  \\\n",
       "0          0        0        0        0        0        0        0        0   \n",
       "1          0        0        0        0        0        0        0        0   \n",
       "2          1        0        0        0        0        0        0        0   \n",
       "3          0        1        0        0        0        0        0        0   \n",
       "4          0        0        1        0        0        0        0        0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "725        0        0        0        0        0        0        0        1   \n",
       "726        0        0        0        0        0        0        0        0   \n",
       "727        0        0        0        0        0        0        0        0   \n",
       "728        0        0        0        0        0        0        0        0   \n",
       "729        0        0        0        0        0        0        0        0   \n",
       "\n",
       "     hour_20  hour_21  hour_22  hour_23  \n",
       "0          0        0        0        0  \n",
       "1          0        0        0        0  \n",
       "2          0        0        0        0  \n",
       "3          0        0        0        0  \n",
       "4          0        0        0        0  \n",
       "..       ...      ...      ...      ...  \n",
       "725        0        0        0        0  \n",
       "726        1        0        0        0  \n",
       "727        0        1        0        0  \n",
       "728        0        0        1        0  \n",
       "729        0        0        0        1  \n",
       "\n",
       "[730 rows x 50 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_one_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from tensorflow.keras import model_conf\n",
    "from keras.layers import BatchNormalization, Dense, Add \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "def residual_block(x):\n",
    "  x_skip = x\n",
    "  x = Dense(model_conf['neuron_size'],activation='relu',kernel_regularizer=model_conf['regulizer'])(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Dropout(model_conf['dropout'])(x)\n",
    "\n",
    "  x = Dense(model_conf['neuron_size'],activation='relu',kernel_regularizer=model_conf['regulizer'])(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Dropout(model_conf['dropout'])(x)\n",
    "\n",
    "  adding = Add()([x_skip,x])\n",
    "  return Activation('relu')(adding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "sns.heatmap(onehot_encoded.iloc[:,:11].corr(), cmap = 'copper',annot = True)\n",
    "plt.title('Heat Map for Correlations', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = target[:7692]\n",
    "test = target[7692:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = train.copy()\n",
    "x_test = test.copy()\n",
    "\n",
    "y_train = x_train.pop('Production')\n",
    "y_test = x_test.pop('Production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_one_year.copy()\n",
    "x_test = test_one_week.copy()\n",
    "\n",
    "y_train = x_train.pop('Production')\n",
    "y_test = x_test.pop('Production')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = normalized[\"Production\"]\n",
    "x = normalized.drop(\"Production\",axis=1)\n",
    "#train test split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.8,shuffle=False,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clfs = []\n",
    "seed = 3\n",
    "\n",
    "clfs.append((\"LinearRegression\", Pipeline([(\"LogReg\", LinearRegression())])))\n",
    "\n",
    "clfs.append((\"XGB\", Pipeline([(\"XGB\", XGBRegressor())]))) \n",
    "\n",
    "clfs.append((\"KNN\", Pipeline([(\"KNN\", KNeighborsRegressor())]))) \n",
    "\n",
    "clfs.append((\"DTR\", Pipeline([(\"DecisionTrees\", DecisionTreeRegressor())]))) \n",
    "\n",
    "clfs.append((\"RFRegressor\", Pipeline([(\"RandomForest\", RandomForestRegressor())]))) \n",
    "\n",
    "clfs.append((\"GBRegressor\", Pipeline([(\"GradientBoosting\", GradientBoostingRegressor())]))) \n",
    "\n",
    "clfs.append((\"MLP\", Pipeline([(\"MLP Regressor\", MLPRegressor())])))\n",
    "\n",
    "clfs.append((\"EXT Regressor\",Pipeline([(\"ExtraTrees\", ExtraTreeRegressor())])))\n",
    "\n",
    "clfs.append((\"SV Regressor\", Pipeline([(\"ExtraTrees\", SVR())])))\n",
    "\n",
    "scoring = 'r2'\n",
    "n_folds = 10\n",
    "msgs = []\n",
    "results, names  = [], [] \n",
    "\n",
    "for name, model  in clfs:\n",
    "    kfold = KFold(n_splits=n_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring, n_jobs=-1)    \n",
    "    names.append(name)\n",
    "    results.append(cv_results)    \n",
    "    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msgs.append(msg)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,make_scorer,r2_score,mean_absolute_percentage_error,explained_variance_score\n",
    "\n",
    "def metrics(y_train1,y_train_pred1,y_test1,y_test_pred1):\n",
    "    print(\"for train data, mean squared error is\",mean_squared_error(y_train1, y_train_pred1))\n",
    "    print(\"for train data, mean absolute error is:\",mean_absolute_error(y_train1, y_train_pred1))\n",
    "    print(\"for train data, mean absolute percentage error is\",mean_absolute_percentage_error(y_train1, y_train_pred1),\"\\n\")\n",
    "\n",
    "    print(\"for test data, mean squared error is\",mean_squared_error(y_test1, y_test_pred1))\n",
    "    print(\"for test data, mean absolute error is:\",mean_absolute_error(y_test1, y_test_pred1))\n",
    "    print(\"for test data, mean absolute percentage error is\",mean_absolute_percentage_error(y_test1, y_test_pred1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_compile_model():\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1899 - mean_absolute_error: 0.1899\n",
      "Epoch 2/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0773 - mean_absolute_error: 0.0773\n",
      "Epoch 3/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0698 - mean_absolute_error: 0.0698\n",
      "Epoch 4/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0654 - mean_absolute_error: 0.0654\n",
      "Epoch 5/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0634 - mean_absolute_error: 0.0634\n",
      "Epoch 6/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0622 - mean_absolute_error: 0.0622\n",
      "Epoch 7/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0612 - mean_absolute_error: 0.0612\n",
      "Epoch 8/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0594 - mean_absolute_error: 0.0594\n",
      "Epoch 9/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0588 - mean_absolute_error: 0.0588\n",
      "Epoch 10/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0579 - mean_absolute_error: 0.0579\n",
      "Epoch 11/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0571 - mean_absolute_error: 0.0571\n",
      "Epoch 12/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0571 - mean_absolute_error: 0.0571\n",
      "Epoch 13/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0570 - mean_absolute_error: 0.0570\n",
      "Epoch 14/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0562 - mean_absolute_error: 0.0562\n",
      "Epoch 15/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0554 - mean_absolute_error: 0.0554\n",
      "Epoch 16/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0554 - mean_absolute_error: 0.0554\n",
      "Epoch 17/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0553 - mean_absolute_error: 0.0553\n",
      "Epoch 18/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0547 - mean_absolute_error: 0.0547\n",
      "Epoch 19/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0545 - mean_absolute_error: 0.0545\n",
      "Epoch 20/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0544 - mean_absolute_error: 0.0544\n",
      "Epoch 21/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0545 - mean_absolute_error: 0.0545\n",
      "Epoch 22/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0545 - mean_absolute_error: 0.0545\n",
      "Epoch 23/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0544 - mean_absolute_error: 0.0544\n",
      "Epoch 24/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0531 - mean_absolute_error: 0.0531\n",
      "Epoch 25/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0532 - mean_absolute_error: 0.0532\n",
      "Epoch 26/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0528 - mean_absolute_error: 0.0528\n",
      "Epoch 27/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0528 - mean_absolute_error: 0.0528\n",
      "Epoch 28/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0527 - mean_absolute_error: 0.0527\n",
      "Epoch 29/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0528 - mean_absolute_error: 0.0528\n",
      "Epoch 30/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0520 - mean_absolute_error: 0.0520\n",
      "Epoch 31/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0523 - mean_absolute_error: 0.0523\n",
      "Epoch 32/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0522 - mean_absolute_error: 0.0522\n",
      "Epoch 33/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0512 - mean_absolute_error: 0.0512\n",
      "Epoch 34/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0513 - mean_absolute_error: 0.0513\n",
      "Epoch 35/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0522 - mean_absolute_error: 0.0522\n",
      "Epoch 36/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0514 - mean_absolute_error: 0.0514\n",
      "Epoch 37/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0509 - mean_absolute_error: 0.0509\n",
      "Epoch 38/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0507 - mean_absolute_error: 0.0507\n",
      "Epoch 39/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0501 - mean_absolute_error: 0.0501\n",
      "Epoch 40/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0505 - mean_absolute_error: 0.0505\n",
      "Epoch 41/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0503 - mean_absolute_error: 0.0503\n",
      "Epoch 42/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0501 - mean_absolute_error: 0.0501\n",
      "Epoch 43/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0493 - mean_absolute_error: 0.0493\n",
      "Epoch 44/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0500 - mean_absolute_error: 0.0500\n",
      "Epoch 45/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0490 - mean_absolute_error: 0.0490\n",
      "Epoch 46/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0488 - mean_absolute_error: 0.0488\n",
      "Epoch 47/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0495 - mean_absolute_error: 0.0495\n",
      "Epoch 48/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0491 - mean_absolute_error: 0.0491\n",
      "Epoch 49/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0494 - mean_absolute_error: 0.0494\n",
      "Epoch 50/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0488 - mean_absolute_error: 0.0488\n",
      "Epoch 51/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0486 - mean_absolute_error: 0.0486\n",
      "Epoch 52/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0483 - mean_absolute_error: 0.0483\n",
      "Epoch 53/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0485 - mean_absolute_error: 0.0485\n",
      "Epoch 54/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0479 - mean_absolute_error: 0.0479\n",
      "Epoch 55/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0481 - mean_absolute_error: 0.0481\n",
      "Epoch 56/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0484 - mean_absolute_error: 0.0484\n",
      "Epoch 57/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0487 - mean_absolute_error: 0.0487\n",
      "Epoch 58/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0486 - mean_absolute_error: 0.0486\n",
      "Epoch 59/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0476 - mean_absolute_error: 0.0476\n",
      "Epoch 60/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0477 - mean_absolute_error: 0.0477\n",
      "Epoch 61/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0473 - mean_absolute_error: 0.0473\n",
      "Epoch 62/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0470 - mean_absolute_error: 0.0470\n",
      "Epoch 63/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0472 - mean_absolute_error: 0.0472\n",
      "Epoch 64/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0466 - mean_absolute_error: 0.0466\n",
      "Epoch 65/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0472 - mean_absolute_error: 0.0472\n",
      "Epoch 66/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0472 - mean_absolute_error: 0.0472\n",
      "Epoch 67/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0474 - mean_absolute_error: 0.0474\n",
      "Epoch 68/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0463 - mean_absolute_error: 0.0463\n",
      "Epoch 69/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0465 - mean_absolute_error: 0.0465\n",
      "Epoch 70/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0461 - mean_absolute_error: 0.0461\n",
      "Epoch 71/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0461 - mean_absolute_error: 0.0461\n",
      "Epoch 72/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0459 - mean_absolute_error: 0.0459\n",
      "Epoch 73/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0460 - mean_absolute_error: 0.0460\n",
      "Epoch 74/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0462 - mean_absolute_error: 0.0462\n",
      "Epoch 75/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0462 - mean_absolute_error: 0.0462\n",
      "Epoch 76/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0463 - mean_absolute_error: 0.0463\n",
      "Epoch 77/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0460 - mean_absolute_error: 0.0460\n",
      "Epoch 78/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0456 - mean_absolute_error: 0.0456\n",
      "Epoch 79/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0455 - mean_absolute_error: 0.0455\n",
      "Epoch 80/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0457 - mean_absolute_error: 0.0457\n",
      "Epoch 81/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0455 - mean_absolute_error: 0.0455\n",
      "Epoch 82/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0451 - mean_absolute_error: 0.0451\n",
      "Epoch 83/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0452 - mean_absolute_error: 0.0452\n",
      "Epoch 84/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0448 - mean_absolute_error: 0.0448\n",
      "Epoch 85/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0448 - mean_absolute_error: 0.0448\n",
      "Epoch 86/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0457 - mean_absolute_error: 0.0457\n",
      "Epoch 87/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0451 - mean_absolute_error: 0.0451\n",
      "Epoch 88/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0453 - mean_absolute_error: 0.0453\n",
      "Epoch 89/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0444 - mean_absolute_error: 0.0444\n",
      "Epoch 90/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0447 - mean_absolute_error: 0.0447\n",
      "Epoch 91/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0451 - mean_absolute_error: 0.0451\n",
      "Epoch 92/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0450 - mean_absolute_error: 0.0450\n",
      "Epoch 93/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0447 - mean_absolute_error: 0.0447\n",
      "Epoch 94/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0439 - mean_absolute_error: 0.0439\n",
      "Epoch 95/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0450 - mean_absolute_error: 0.0450\n",
      "Epoch 96/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0445 - mean_absolute_error: 0.0445\n",
      "Epoch 97/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0441 - mean_absolute_error: 0.0441\n",
      "Epoch 98/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0441 - mean_absolute_error: 0.0441\n",
      "Epoch 99/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0436 - mean_absolute_error: 0.0436\n",
      "Epoch 100/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0436 - mean_absolute_error: 0.0436\n",
      "Epoch 101/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0442 - mean_absolute_error: 0.0442\n",
      "Epoch 102/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0440 - mean_absolute_error: 0.0440\n",
      "Epoch 103/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0446 - mean_absolute_error: 0.0446\n",
      "Epoch 104/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0439 - mean_absolute_error: 0.0439\n",
      "Epoch 105/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0443 - mean_absolute_error: 0.0443\n",
      "Epoch 106/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0436 - mean_absolute_error: 0.0436\n",
      "Epoch 107/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0436 - mean_absolute_error: 0.0436\n",
      "Epoch 108/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0436 - mean_absolute_error: 0.0436\n",
      "Epoch 109/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0435 - mean_absolute_error: 0.0435\n",
      "Epoch 110/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0432 - mean_absolute_error: 0.0432\n",
      "Epoch 111/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0431 - mean_absolute_error: 0.0431\n",
      "Epoch 112/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0436 - mean_absolute_error: 0.0436\n",
      "Epoch 113/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0432 - mean_absolute_error: 0.0432\n",
      "Epoch 114/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0435 - mean_absolute_error: 0.0435\n",
      "Epoch 115/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0430 - mean_absolute_error: 0.0430\n",
      "Epoch 116/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0429 - mean_absolute_error: 0.0429\n",
      "Epoch 117/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0432 - mean_absolute_error: 0.0432A: 0s - loss: 0.0422 - mean_absolute_error: 0.042\n",
      "Epoch 118/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0438 - mean_absolute_error: 0.0438\n",
      "Epoch 119/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0425 - mean_absolute_error: 0.0425\n",
      "Epoch 120/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0433 - mean_absolute_error: 0.0433\n",
      "Epoch 121/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0426 - mean_absolute_error: 0.0426\n",
      "Epoch 122/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0427 - mean_absolute_error: 0.0427\n",
      "Epoch 123/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0423 - mean_absolute_error: 0.0423\n",
      "Epoch 124/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0425 - mean_absolute_error: 0.0425\n",
      "Epoch 125/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0429 - mean_absolute_error: 0.0429\n",
      "Epoch 126/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0427 - mean_absolute_error: 0.0427\n",
      "Epoch 127/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0426 - mean_absolute_error: 0.0426\n",
      "Epoch 128/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0424 - mean_absolute_error: 0.0424\n",
      "Epoch 129/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0423 - mean_absolute_error: 0.0423\n",
      "Epoch 130/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0424 - mean_absolute_error: 0.0424\n",
      "Epoch 131/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0419 - mean_absolute_error: 0.0419\n",
      "Epoch 132/200\n",
      "121/121 [==============================] - 0s 1000us/step - loss: 0.0420 - mean_absolute_error: 0.0420\n",
      "Epoch 133/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0427 - mean_absolute_error: 0.0427\n",
      "Epoch 134/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0421 - mean_absolute_error: 0.0421\n",
      "Epoch 135/200\n",
      "121/121 [==============================] - 0s 958us/step - loss: 0.0420 - mean_absolute_error: 0.0420\n",
      "Epoch 136/200\n",
      "121/121 [==============================] - 0s 975us/step - loss: 0.0421 - mean_absolute_error: 0.0421\n",
      "Epoch 137/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0421 - mean_absolute_error: 0.0421\n",
      "Epoch 138/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0418 - mean_absolute_error: 0.0418\n",
      "Epoch 139/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0419 - mean_absolute_error: 0.0419\n",
      "Epoch 140/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0415 - mean_absolute_error: 0.0415\n",
      "Epoch 141/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0424 - mean_absolute_error: 0.0424\n",
      "Epoch 142/200\n",
      "121/121 [==============================] - 0s 933us/step - loss: 0.0416 - mean_absolute_error: 0.0416\n",
      "Epoch 143/200\n",
      "121/121 [==============================] - 0s 925us/step - loss: 0.0417 - mean_absolute_error: 0.0417\n",
      "Epoch 144/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0423 - mean_absolute_error: 0.0423\n",
      "Epoch 145/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0415 - mean_absolute_error: 0.0415\n",
      "Epoch 146/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0417 - mean_absolute_error: 0.0417\n",
      "Epoch 147/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0409 - mean_absolute_error: 0.0409\n",
      "Epoch 148/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0420 - mean_absolute_error: 0.0420\n",
      "Epoch 149/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0414 - mean_absolute_error: 0.0414\n",
      "Epoch 150/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0412 - mean_absolute_error: 0.0412\n",
      "Epoch 151/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0412 - mean_absolute_error: 0.0412\n",
      "Epoch 152/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0405 - mean_absolute_error: 0.0405\n",
      "Epoch 153/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0413 - mean_absolute_error: 0.0413\n",
      "Epoch 154/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0417 - mean_absolute_error: 0.0417\n",
      "Epoch 155/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0410 - mean_absolute_error: 0.0410\n",
      "Epoch 156/200\n",
      "121/121 [==============================] - 0s 1000us/step - loss: 0.0408 - mean_absolute_error: 0.0408\n",
      "Epoch 157/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0406 - mean_absolute_error: 0.0406\n",
      "Epoch 158/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0406 - mean_absolute_error: 0.0406\n",
      "Epoch 159/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0412 - mean_absolute_error: 0.0412\n",
      "Epoch 160/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0413 - mean_absolute_error: 0.0413\n",
      "Epoch 161/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0406 - mean_absolute_error: 0.0406\n",
      "Epoch 162/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0416 - mean_absolute_error: 0.0416\n",
      "Epoch 163/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0404 - mean_absolute_error: 0.0404\n",
      "Epoch 164/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0406 - mean_absolute_error: 0.0406\n",
      "Epoch 165/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0411 - mean_absolute_error: 0.0411\n",
      "Epoch 166/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0405 - mean_absolute_error: 0.0405\n",
      "Epoch 167/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0401 - mean_absolute_error: 0.0401\n",
      "Epoch 168/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0403 - mean_absolute_error: 0.0403\n",
      "Epoch 169/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0403 - mean_absolute_error: 0.0403\n",
      "Epoch 170/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0407 - mean_absolute_error: 0.0407\n",
      "Epoch 171/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0401 - mean_absolute_error: 0.0401\n",
      "Epoch 172/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0407 - mean_absolute_error: 0.0407\n",
      "Epoch 173/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0403 - mean_absolute_error: 0.0403\n",
      "Epoch 174/200\n",
      "121/121 [==============================] - 0s 983us/step - loss: 0.0396 - mean_absolute_error: 0.0396\n",
      "Epoch 175/200\n",
      "121/121 [==============================] - 0s 958us/step - loss: 0.0409 - mean_absolute_error: 0.0409\n",
      "Epoch 176/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0400 - mean_absolute_error: 0.0400\n",
      "Epoch 177/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0402 - mean_absolute_error: 0.0402\n",
      "Epoch 178/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0401 - mean_absolute_error: 0.0401\n",
      "Epoch 179/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0401 - mean_absolute_error: 0.0401\n",
      "Epoch 180/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0406 - mean_absolute_error: 0.0406\n",
      "Epoch 181/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0403 - mean_absolute_error: 0.0403\n",
      "Epoch 182/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_absolute_error: 0.0396\n",
      "Epoch 183/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0406 - mean_absolute_error: 0.0406\n",
      "Epoch 184/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0400 - mean_absolute_error: 0.0400\n",
      "Epoch 185/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0398 - mean_absolute_error: 0.0398\n",
      "Epoch 186/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0394 - mean_absolute_error: 0.0394\n",
      "Epoch 187/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0395 - mean_absolute_error: 0.0395\n",
      "Epoch 188/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0398 - mean_absolute_error: 0.0398\n",
      "Epoch 189/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_absolute_error: 0.0396\n",
      "Epoch 190/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0395 - mean_absolute_error: 0.0395\n",
      "Epoch 191/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0397 - mean_absolute_error: 0.0397\n",
      "Epoch 192/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0395 - mean_absolute_error: 0.0395\n",
      "Epoch 193/200\n",
      "121/121 [==============================] - 0s 950us/step - loss: 0.0391 - mean_absolute_error: 0.0391\n",
      "Epoch 194/200\n",
      "121/121 [==============================] - 0s 983us/step - loss: 0.0394 - mean_absolute_error: 0.0394\n",
      "Epoch 195/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_absolute_error: 0.0396\n",
      "Epoch 196/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0399 - mean_absolute_error: 0.0399\n",
      "Epoch 197/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0399 - mean_absolute_error: 0.0399\n",
      "Epoch 198/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0393 - mean_absolute_error: 0.0393\n",
      "Epoch 199/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0390 - mean_absolute_error: 0.0390\n",
      "Epoch 200/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0390 - mean_absolute_error: 0.0390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e48b6b00>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = build_and_compile_model()\n",
    "ali.fit(x_train,y_train,batch_size=64,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "121/121 [==============================] - 1s 1ms/step - loss: 0.3163 - mean_absolute_error: 0.4520\n",
      "Epoch 2/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0579 - mean_absolute_error: 0.1720\n",
      "Epoch 3/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0391 - mean_absolute_error: 0.1273\n",
      "Epoch 4/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0322 - mean_absolute_error: 0.1049\n",
      "Epoch 5/200\n",
      "121/121 [==============================] - 0s 1000us/step - loss: 0.0297 - mean_absolute_error: 0.0947\n",
      "Epoch 6/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0285 - mean_absolute_error: 0.0903\n",
      "Epoch 7/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0278 - mean_absolute_error: 0.0880\n",
      "Epoch 8/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0273 - mean_absolute_error: 0.0852\n",
      "Epoch 9/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0269 - mean_absolute_error: 0.0843\n",
      "Epoch 10/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0265 - mean_absolute_error: 0.0824\n",
      "Epoch 11/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0262 - mean_absolute_error: 0.0810\n",
      "Epoch 12/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0259 - mean_absolute_error: 0.0801\n",
      "Epoch 13/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0256 - mean_absolute_error: 0.0790\n",
      "Epoch 14/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_absolute_error: 0.0780\n",
      "Epoch 15/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0251 - mean_absolute_error: 0.0773\n",
      "Epoch 16/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0249 - mean_absolute_error: 0.0772\n",
      "Epoch 17/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_absolute_error: 0.0761\n",
      "Epoch 18/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0244 - mean_absolute_error: 0.0747\n",
      "Epoch 19/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_absolute_error: 0.0740\n",
      "Epoch 20/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_absolute_error: 0.0735\n",
      "Epoch 21/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0240 - mean_absolute_error: 0.0728\n",
      "Epoch 22/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0238 - mean_absolute_error: 0.0724\n",
      "Epoch 23/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0238 - mean_absolute_error: 0.0723\n",
      "Epoch 24/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0236 - mean_absolute_error: 0.0714\n",
      "Epoch 25/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0236 - mean_absolute_error: 0.0713\n",
      "Epoch 26/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0233 - mean_absolute_error: 0.0710\n",
      "Epoch 27/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0234 - mean_absolute_error: 0.0712\n",
      "Epoch 28/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0232 - mean_absolute_error: 0.0708\n",
      "Epoch 29/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0231 - mean_absolute_error: 0.0706\n",
      "Epoch 30/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0231 - mean_absolute_error: 0.0696\n",
      "Epoch 31/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_absolute_error: 0.0694\n",
      "Epoch 32/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_absolute_error: 0.0683\n",
      "Epoch 33/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_absolute_error: 0.0709\n",
      "Epoch 34/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_absolute_error: 0.0698\n",
      "Epoch 35/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0226 - mean_absolute_error: 0.0682A: 0s - loss: 0.0217 - mean_absolute_error: 0.06\n",
      "Epoch 36/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0224 - mean_absolute_error: 0.0684\n",
      "Epoch 37/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0223 - mean_absolute_error: 0.0676\n",
      "Epoch 38/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0224 - mean_absolute_error: 0.0689\n",
      "Epoch 39/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0223 - mean_absolute_error: 0.0680\n",
      "Epoch 40/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0222 - mean_absolute_error: 0.0683\n",
      "Epoch 41/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0222 - mean_absolute_error: 0.0679\n",
      "Epoch 42/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0219 - mean_absolute_error: 0.0674\n",
      "Epoch 43/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0219 - mean_absolute_error: 0.0669\n",
      "Epoch 44/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0219 - mean_absolute_error: 0.0680\n",
      "Epoch 45/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0218 - mean_absolute_error: 0.0661\n",
      "Epoch 46/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0217 - mean_absolute_error: 0.0672\n",
      "Epoch 47/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0217 - mean_absolute_error: 0.0670\n",
      "Epoch 48/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_absolute_error: 0.0660\n",
      "Epoch 49/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0215 - mean_absolute_error: 0.0670\n",
      "Epoch 50/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_absolute_error: 0.0660\n",
      "Epoch 51/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_absolute_error: 0.0681\n",
      "Epoch 52/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0212 - mean_absolute_error: 0.0659\n",
      "Epoch 53/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0211 - mean_absolute_error: 0.0659\n",
      "Epoch 54/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0211 - mean_absolute_error: 0.0657\n",
      "Epoch 55/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0211 - mean_absolute_error: 0.0660\n",
      "Epoch 56/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0210 - mean_absolute_error: 0.0659\n",
      "Epoch 57/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0210 - mean_absolute_error: 0.0657\n",
      "Epoch 58/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0208 - mean_absolute_error: 0.0653A: 0s - loss: 0.0201 - mean_absolute_error: 0.06\n",
      "Epoch 59/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0209 - mean_absolute_error: 0.0661\n",
      "Epoch 60/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0207 - mean_absolute_error: 0.0650\n",
      "Epoch 61/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0210 - mean_absolute_error: 0.0666\n",
      "Epoch 62/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0207 - mean_absolute_error: 0.0651\n",
      "Epoch 63/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0206 - mean_absolute_error: 0.0650\n",
      "Epoch 64/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0205 - mean_absolute_error: 0.0644\n",
      "Epoch 65/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0205 - mean_absolute_error: 0.0644\n",
      "Epoch 66/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0204 - mean_absolute_error: 0.0641\n",
      "Epoch 67/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0205 - mean_absolute_error: 0.0643\n",
      "Epoch 68/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0204 - mean_absolute_error: 0.0639\n",
      "Epoch 69/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0203 - mean_absolute_error: 0.0638\n",
      "Epoch 70/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0203 - mean_absolute_error: 0.0642A: 0s - loss: 0.0209 - mean_absolute_error: 0.064\n",
      "Epoch 71/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0203 - mean_absolute_error: 0.0644\n",
      "Epoch 72/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0641\n",
      "Epoch 73/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0203 - mean_absolute_error: 0.0647\n",
      "Epoch 74/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0650\n",
      "Epoch 75/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0644A: 0s - loss: 0.0195 - mean_absolute_error: 0.06\n",
      "Epoch 76/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0201 - mean_absolute_error: 0.0642\n",
      "Epoch 77/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0643\n",
      "Epoch 78/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0200 - mean_absolute_error: 0.0638\n",
      "Epoch 79/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0201 - mean_absolute_error: 0.0643\n",
      "Epoch 80/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0200 - mean_absolute_error: 0.0646\n",
      "Epoch 81/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0200 - mean_absolute_error: 0.0643\n",
      "Epoch 82/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_absolute_error: 0.0641\n",
      "Epoch 83/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_absolute_error: 0.0629\n",
      "Epoch 84/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_absolute_error: 0.0640\n",
      "Epoch 85/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_absolute_error: 0.0633\n",
      "Epoch 86/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0198 - mean_absolute_error: 0.0627\n",
      "Epoch 87/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_absolute_error: 0.0647\n",
      "Epoch 88/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0197 - mean_absolute_error: 0.0640\n",
      "Epoch 89/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0199 - mean_absolute_error: 0.0644\n",
      "Epoch 90/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0198 - mean_absolute_error: 0.0641\n",
      "Epoch 91/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0661\n",
      "Epoch 92/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0197 - mean_absolute_error: 0.0626\n",
      "Epoch 93/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.0632\n",
      "Epoch 94/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.0631\n",
      "Epoch 95/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0198 - mean_absolute_error: 0.0647\n",
      "Epoch 96/200\n",
      "121/121 [==============================] - 0s 908us/step - loss: 0.0196 - mean_absolute_error: 0.0632\n",
      "Epoch 97/200\n",
      "121/121 [==============================] - 0s 925us/step - loss: 0.0197 - mean_absolute_error: 0.0637\n",
      "Epoch 98/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.0635\n",
      "Epoch 99/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0627\n",
      "Epoch 100/200\n",
      "121/121 [==============================] - 0s 1000us/step - loss: 0.0195 - mean_absolute_error: 0.0636\n",
      "Epoch 101/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.0635\n",
      "Epoch 102/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0632\n",
      "Epoch 103/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0624\n",
      "Epoch 104/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0634\n",
      "Epoch 105/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0635\n",
      "Epoch 106/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_absolute_error: 0.0628\n",
      "Epoch 107/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_absolute_error: 0.0626\n",
      "Epoch 108/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_absolute_error: 0.0629\n",
      "Epoch 109/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_absolute_error: 0.0621A: 0s - loss: 0.0166 - mean_absolute_error: 0.05\n",
      "Epoch 110/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.0643\n",
      "Epoch 111/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_absolute_error: 0.0623\n",
      "Epoch 112/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_absolute_error: 0.0628\n",
      "Epoch 113/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_absolute_error: 0.0633\n",
      "Epoch 114/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0192 - mean_absolute_error: 0.0626\n",
      "Epoch 115/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0620\n",
      "Epoch 116/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_absolute_error: 0.0626\n",
      "Epoch 117/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0615\n",
      "Epoch 118/200\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0194 - mean_absolute_error: 0.0647\n",
      "Epoch 119/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0193 - mean_absolute_error: 0.0639\n",
      "Epoch 120/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0618\n",
      "Epoch 121/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0192 - mean_absolute_error: 0.0627\n",
      "Epoch 122/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0192 - mean_absolute_error: 0.0635\n",
      "Epoch 123/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0615\n",
      "Epoch 124/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0616\n",
      "Epoch 125/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0630\n",
      "Epoch 126/200\n",
      "121/121 [==============================] - 0s 992us/step - loss: 0.0192 - mean_absolute_error: 0.0628\n",
      "Epoch 127/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0628\n",
      "Epoch 128/200\n",
      "121/121 [==============================] - 0s 975us/step - loss: 0.0190 - mean_absolute_error: 0.0616\n",
      "Epoch 129/200\n",
      "121/121 [==============================] - 0s 942us/step - loss: 0.0191 - mean_absolute_error: 0.0627\n",
      "Epoch 130/200\n",
      "121/121 [==============================] - 0s 950us/step - loss: 0.0190 - mean_absolute_error: 0.0626\n",
      "Epoch 131/200\n",
      "121/121 [==============================] - 0s 908us/step - loss: 0.0191 - mean_absolute_error: 0.0652\n",
      "Epoch 132/200\n",
      "121/121 [==============================] - 0s 950us/step - loss: 0.0190 - mean_absolute_error: 0.0616\n",
      "Epoch 133/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0629\n",
      "Epoch 134/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0192 - mean_absolute_error: 0.0638\n",
      "Epoch 135/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0624\n",
      "Epoch 136/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0612\n",
      "Epoch 137/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0616\n",
      "Epoch 138/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0621\n",
      "Epoch 139/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0191 - mean_absolute_error: 0.0638\n",
      "Epoch 140/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0613\n",
      "Epoch 141/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0631\n",
      "Epoch 142/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0620\n",
      "Epoch 143/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0621\n",
      "Epoch 144/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0611\n",
      "Epoch 145/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0190 - mean_absolute_error: 0.0624\n",
      "Epoch 146/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0621\n",
      "Epoch 147/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0618\n",
      "Epoch 148/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0626A: 0s - loss: 0.0190 - mean_absolute_error: 0.063\n",
      "Epoch 149/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0613\n",
      "Epoch 150/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0612\n",
      "Epoch 151/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0609\n",
      "Epoch 152/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0616\n",
      "Epoch 153/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0613\n",
      "Epoch 154/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0614\n",
      "Epoch 155/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0606\n",
      "Epoch 156/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0623\n",
      "Epoch 157/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0624\n",
      "Epoch 158/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0634\n",
      "Epoch 159/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0614\n",
      "Epoch 160/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0634A: 0s - loss: 0.0195 - mean_absolute_error: 0.06\n",
      "Epoch 161/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0615\n",
      "Epoch 162/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0606\n",
      "Epoch 163/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0609\n",
      "Epoch 164/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0612\n",
      "Epoch 165/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0610\n",
      "Epoch 166/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0612A: 0s - loss: 0.0182 - mean_absolute_error: 0.06\n",
      "Epoch 167/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0613\n",
      "Epoch 168/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0619\n",
      "Epoch 169/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0612\n",
      "Epoch 170/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0624\n",
      "Epoch 171/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0606\n",
      "Epoch 172/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0598\n",
      "Epoch 173/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0620A: 0s - loss: 0.0183 - mean_absolute_error: 0.061\n",
      "Epoch 174/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0621\n",
      "Epoch 175/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0605\n",
      "Epoch 176/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0606\n",
      "Epoch 177/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0627\n",
      "Epoch 178/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0606\n",
      "Epoch 179/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0609\n",
      "Epoch 180/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0606\n",
      "Epoch 181/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0610\n",
      "Epoch 182/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0624\n",
      "Epoch 183/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0608\n",
      "Epoch 184/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0605\n",
      "Epoch 185/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0187 - mean_absolute_error: 0.0635\n",
      "Epoch 186/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0624\n",
      "Epoch 187/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0604\n",
      "Epoch 188/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0609\n",
      "Epoch 189/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0612\n",
      "Epoch 190/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0619\n",
      "Epoch 191/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0186 - mean_absolute_error: 0.0632\n",
      "Epoch 192/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0606\n",
      "Epoch 193/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0613\n",
      "Epoch 194/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0616\n",
      "Epoch 195/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0602A: 0s - loss: 0.0176 - mean_absolute_error: 0.059\n",
      "Epoch 196/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0607\n",
      "Epoch 197/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0622\n",
      "Epoch 198/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0615\n",
      "Epoch 199/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0184 - mean_absolute_error: 0.0612\n",
      "Epoch 200/200\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0609\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4e473f978>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "my_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=16,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=8,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=1,activation=\"linear\")\n",
    "])\n",
    "\n",
    "my_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "    loss='mse')\n",
    "\n",
    "my_model.fit(x_train,y_train,batch_size=64,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.1230 - mean_absolute_error: 0.2616\n",
      "Epoch 2/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0425 - mean_absolute_error: 0.1380\n",
      "Epoch 3/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0342 - mean_absolute_error: 0.1135\n",
      "Epoch 4/50\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0312 - mean_absolute_error: 0.1026\n",
      "Epoch 5/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0295 - mean_absolute_error: 0.0958\n",
      "Epoch 6/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0284 - mean_absolute_error: 0.0901\n",
      "Epoch 7/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0277 - mean_absolute_error: 0.0870\n",
      "Epoch 8/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0272 - mean_absolute_error: 0.0846\n",
      "Epoch 9/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0268 - mean_absolute_error: 0.0823\n",
      "Epoch 10/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0264 - mean_absolute_error: 0.0802\n",
      "Epoch 11/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0261 - mean_absolute_error: 0.0786\n",
      "Epoch 12/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0258 - mean_absolute_error: 0.0774\n",
      "Epoch 13/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0256 - mean_absolute_error: 0.0759\n",
      "Epoch 14/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0255 - mean_absolute_error: 0.0772\n",
      "Epoch 15/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0253 - mean_absolute_error: 0.0756\n",
      "Epoch 16/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_absolute_error: 0.0746\n",
      "Epoch 17/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_absolute_error: 0.0768\n",
      "Epoch 18/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0250 - mean_absolute_error: 0.0748\n",
      "Epoch 19/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_absolute_error: 0.0743\n",
      "Epoch 20/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0247 - mean_absolute_error: 0.0737\n",
      "Epoch 21/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_absolute_error: 0.0728\n",
      "Epoch 22/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_absolute_error: 0.0722\n",
      "Epoch 23/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_absolute_error: 0.0724\n",
      "Epoch 24/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0244 - mean_absolute_error: 0.0721\n",
      "Epoch 25/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_absolute_error: 0.0729\n",
      "Epoch 26/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_absolute_error: 0.0720\n",
      "Epoch 27/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0244 - mean_absolute_error: 0.0719\n",
      "Epoch 28/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0244 - mean_absolute_error: 0.0726\n",
      "Epoch 29/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0243 - mean_absolute_error: 0.0726A: 0s - loss: 0.0251 - mean_absolute_error: 0.07\n",
      "Epoch 30/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_absolute_error: 0.0711\n",
      "Epoch 31/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_absolute_error: 0.0718\n",
      "Epoch 32/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_absolute_error: 0.0719\n",
      "Epoch 33/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0241 - mean_absolute_error: 0.0719\n",
      "Epoch 34/50\n",
      "121/121 [==============================] - 0s 2ms/step - loss: 0.0240 - mean_absolute_error: 0.0710\n",
      "Epoch 35/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_absolute_error: 0.0715\n",
      "Epoch 36/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_absolute_error: 0.0735\n",
      "Epoch 37/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0239 - mean_absolute_error: 0.0718\n",
      "Epoch 38/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_absolute_error: 0.0712\n",
      "Epoch 39/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0240 - mean_absolute_error: 0.0711\n",
      "Epoch 40/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0238 - mean_absolute_error: 0.0719\n",
      "Epoch 41/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0238 - mean_absolute_error: 0.0721A: 0s - loss: 0.0226 - mean_absolute_error: 0.07\n",
      "Epoch 42/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0236 - mean_absolute_error: 0.0708\n",
      "Epoch 43/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_absolute_error: 0.0714\n",
      "Epoch 44/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0238 - mean_absolute_error: 0.0730\n",
      "Epoch 45/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0236 - mean_absolute_error: 0.0704\n",
      "Epoch 46/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0237 - mean_absolute_error: 0.0713\n",
      "Epoch 47/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0236 - mean_absolute_error: 0.0715\n",
      "Epoch 48/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0235 - mean_absolute_error: 0.0714\n",
      "Epoch 49/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0235 - mean_absolute_error: 0.0711\n",
      "Epoch 50/50\n",
      "121/121 [==============================] - 0s 1ms/step - loss: 0.0234 - mean_absolute_error: 0.0709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e4d8cf6a20>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "exp_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=16,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(units=1,activation=\"linear\")\n",
    "])\n",
    "\n",
    "exp_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()],\n",
    "    loss='mse')\n",
    "\n",
    "exp_model.fit(x_train,y_train,batch_size=64,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train data, mean squared error is 0.0329\n",
      "for train data, mean absolute error is: 0.10639\n",
      "for train data, mean absolute percentage error is 0.52634 \n",
      "\n",
      "for test data, mean squared error is 5.604015317551524e+22\n",
      "for test data, mean absolute error is: 236728015189.40512\n",
      "for test data, mean absolute percentage error is 838758352296.1788\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "reg_train_pred = reg.predict(x_train)\n",
    "reg_test_pred = reg.predict(x_test)\n",
    "\n",
    "metrics(y_train,reg_train_pred,y_test,reg_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train data, mean squared error is 0.001585586188426985\n",
      "for train data, mean absolute error is: 0.019847477151901972\n",
      "for train data, mean absolute percentage error is 0.1543493285237681 \n",
      "\n",
      "for test data, mean squared error is 0.03807303537587897\n",
      "for test data, mean absolute error is: 0.08720837932325866\n",
      "for test data, mean absolute percentage error is 0.585500759511294\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb.fit(x_train, y_train)\n",
    "\n",
    "xgb_train_pred = xgb.predict(x_train)\n",
    "xgb_test_pred = xgb.predict(x_test)\n",
    "\n",
    "metrics(y_train,xgb_train_pred,y_test,xgb_test_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train data, mean squared error is 0.02026280612948404\n",
      "for train data, mean absolute error is: 0.055029027987946344\n",
      "for train data, mean absolute percentage error is 0.40131186599042795 \n",
      "\n",
      "for test data, mean squared error is 0.03330210121583113\n",
      "for test data, mean absolute error is: 0.08678253012958088\n",
      "for test data, mean absolute percentage error is 0.5076838732134478\n"
     ]
    }
   ],
   "source": [
    "KN = KNeighborsRegressor()\n",
    "KN.fit(x_train, y_train)\n",
    "\n",
    "KN_train_pred = KN.predict(x_train)\n",
    "KN_test_pred = KN.predict(x_test)\n",
    "\n",
    "metrics(y_train,KN_train_pred,y_test,KN_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train data, mean squared error is 1.922925373491156e-35\n",
      "for train data, mean absolute error is: 1.7320171991032084e-19\n",
      "for train data, mean absolute percentage error is 1.7577437878881462e-19 \n",
      "\n",
      "for test data, mean squared error is 0.06188115997239249\n",
      "for test data, mean absolute error is: 0.10060815273435302\n",
      "for test data, mean absolute percentage error is 0.7264340009546084\n"
     ]
    }
   ],
   "source": [
    "DTree = DecisionTreeRegressor()\n",
    "DTree.fit(x_train, y_train)\n",
    "\n",
    "DTree_train_pred = DTree.predict(x_train)\n",
    "DTree_test_pred = DTree.predict(x_test)\n",
    "\n",
    "metrics(y_train,DTree_train_pred,y_test,DTree_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for train data, mean squared error is 0.0034070034\n",
      "for train data, mean absolute error is: 0.0225874887\n",
      "for train data, mean absolute percentage error is 0.14587 \n",
      "\n",
      "for test data, mean squared error is 0.04225\n",
      "for test data, mean absolute error is: 0.08847\n",
      "for test data, mean absolute percentage error is 0.73682\n"
     ]
    }
   ],
   "source": [
    "r_forest = RandomForestRegressor()\n",
    "r_forest.fit(x_train, y_train)\n",
    "\n",
    "r_forest_train_pred = r_forest.predict(x_train)\n",
    "r_forest_test_pred = r_forest.predict(x_test)\n",
    "\n",
    "metrics(y_train,r_forest_train_pred,y_test,r_forest_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='tanh')\n",
    "  ])\n",
    "\n",
    "new_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.MeanAbsolutePercentageError()],\n",
    "  loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 1s 1ms/step - loss: 0.5707 - mean_absolute_error: 0.6980 - mean_squared_error: 0.5707 - mean_absolute_percentage_error: 115.3837\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.1548 - mean_absolute_error: 0.3346 - mean_squared_error: 0.1548 - mean_absolute_percentage_error: 162.9182\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0892 - mean_absolute_error: 0.2224 - mean_squared_error: 0.0892 - mean_absolute_percentage_error: 142.2835\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0419 - mean_absolute_error: 0.1616 - mean_squared_error: 0.0419 - mean_absolute_percentage_error: 63.1254\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0277 - mean_absolute_error: 0.1103 - mean_squared_error: 0.0277 - mean_absolute_percentage_error: 59.8912\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0233 - mean_absolute_error: 0.0899 - mean_squared_error: 0.0233 - mean_absolute_percentage_error: 55.2966\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0210 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0210 - mean_absolute_percentage_error: 47.9417\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0197 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0197 - mean_absolute_percentage_error: 43.7717\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0185 - mean_absolute_error: 0.0742 - mean_squared_error: 0.0185 - mean_absolute_percentage_error: 40.2249\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0185 - mean_absolute_error: 0.0741 - mean_squared_error: 0.0185 - mean_absolute_percentage_error: 48.0249\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0173 - mean_absolute_error: 0.0684 - mean_squared_error: 0.0173 - mean_absolute_percentage_error: 44.3303\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0174 - mean_absolute_error: 0.0689 - mean_squared_error: 0.0174 - mean_absolute_percentage_error: 46.4632\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0162 - mean_absolute_error: 0.0658 - mean_squared_error: 0.0162 - mean_absolute_percentage_error: 39.8093\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0158 - mean_absolute_error: 0.0631 - mean_squared_error: 0.0158 - mean_absolute_percentage_error: 42.2746\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0152 - mean_absolute_error: 0.0629 - mean_squared_error: 0.0152 - mean_absolute_percentage_error: 45.2051\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0150 - mean_absolute_error: 0.0616 - mean_squared_error: 0.0150 - mean_absolute_percentage_error: 41.3939\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0157 - mean_absolute_error: 0.0623 - mean_squared_error: 0.0157 - mean_absolute_percentage_error: 44.3000\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0149 - mean_absolute_error: 0.0600 - mean_squared_error: 0.0149 - mean_absolute_percentage_error: 42.6351\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0144 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0144 - mean_absolute_percentage_error: 37.3177\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0142 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0142 - mean_absolute_percentage_error: 40.4305\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0145 - mean_absolute_error: 0.0594 - mean_squared_error: 0.0145 - mean_absolute_percentage_error: 39.9464\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0139 - mean_absolute_error: 0.0557 - mean_squared_error: 0.0139 - mean_absolute_percentage_error: 44.3773\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0143 - mean_absolute_error: 0.0596 - mean_squared_error: 0.0143 - mean_absolute_percentage_error: 44.9226\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0145 - mean_absolute_error: 0.0559 - mean_squared_error: 0.0145 - mean_absolute_percentage_error: 44.9417\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0147 - mean_absolute_error: 0.0597 - mean_squared_error: 0.0147 - mean_absolute_percentage_error: 50.0516\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0136 - mean_absolute_error: 0.0569 - mean_squared_error: 0.0136 - mean_absolute_percentage_error: 40.7421\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0132 - mean_absolute_error: 0.0547 - mean_squared_error: 0.0132 - mean_absolute_percentage_error: 41.9937\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_absolute_error: 0.0531 - mean_squared_error: 0.0126 - mean_absolute_percentage_error: 38.8183\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0136 - mean_absolute_error: 0.0559 - mean_squared_error: 0.0136 - mean_absolute_percentage_error: 35.9601\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0129 - mean_absolute_error: 0.0541 - mean_squared_error: 0.0129 - mean_absolute_percentage_error: 40.0056\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0128 - mean_absolute_error: 0.0528 - mean_squared_error: 0.0128 - mean_absolute_percentage_error: 39.6186\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0131 - mean_absolute_error: 0.0544 - mean_squared_error: 0.0131 - mean_absolute_percentage_error: 38.6837\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0135 - mean_absolute_error: 0.0549 - mean_squared_error: 0.0135 - mean_absolute_percentage_error: 48.0893\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0130 - mean_absolute_error: 0.0536 - mean_squared_error: 0.0130 - mean_absolute_percentage_error: 39.2404\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_absolute_error: 0.0511 - mean_squared_error: 0.0121 - mean_absolute_percentage_error: 36.9206\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0118 - mean_absolute_error: 0.0501 - mean_squared_error: 0.0118 - mean_absolute_percentage_error: 36.1432\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_absolute_error: 0.0548 - mean_squared_error: 0.0126 - mean_absolute_percentage_error: 45.4196\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0134 - mean_absolute_error: 0.0540 - mean_squared_error: 0.0134 - mean_absolute_percentage_error: 42.5137\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0511 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 37.9966\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0498 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 33.5649\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0116 - mean_absolute_error: 0.0498 - mean_squared_error: 0.0116 - mean_absolute_percentage_error: 36.3762\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0115 - mean_absolute_error: 0.0490 - mean_squared_error: 0.0115 - mean_absolute_percentage_error: 38.4583\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_absolute_error: 0.0498 - mean_squared_error: 0.0114 - mean_absolute_percentage_error: 33.7054\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0110 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0110 - mean_absolute_percentage_error: 33.9814\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_absolute_error: 0.0482 - mean_squared_error: 0.0111 - mean_absolute_percentage_error: 37.1757\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0113 - mean_absolute_error: 0.0480 - mean_squared_error: 0.0113 - mean_absolute_percentage_error: 37.4973\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_absolute_error: 0.0479 - mean_squared_error: 0.0108 - mean_absolute_percentage_error: 33.4346\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0111 - mean_absolute_percentage_error: 34.7794\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_absolute_error: 0.0462 - mean_squared_error: 0.0105 - mean_absolute_percentage_error: 37.8844\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0460 - mean_squared_error: 0.0102 - mean_absolute_percentage_error: 33.2839\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0460 - mean_squared_error: 0.0102 - mean_absolute_percentage_error: 34.0803\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0457 - mean_squared_error: 0.0102 - mean_absolute_percentage_error: 32.5662   \n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_absolute_error: 0.0465 - mean_squared_error: 0.0107 - mean_absolute_percentage_error: 38.2966\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0454 - mean_squared_error: 0.0101 - mean_absolute_percentage_error: 31.9153\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0102 - mean_absolute_error: 0.0453 - mean_squared_error: 0.0102 - mean_absolute_percentage_error: 35.2042\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_absolute_error: 0.0441 - mean_squared_error: 0.0100 - mean_absolute_percentage_error: 33.2421\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0095 - mean_absolute_error: 0.0435 - mean_squared_error: 0.0095 - mean_absolute_percentage_error: 33.2103\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_absolute_error: 0.0450 - mean_squared_error: 0.0104 - mean_absolute_percentage_error: 32.0292\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_absolute_error: 0.0462 - mean_squared_error: 0.0105 - mean_absolute_percentage_error: 36.0633\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0104 - mean_absolute_error: 0.0453 - mean_squared_error: 0.0104 - mean_absolute_percentage_error: 38.4679\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_absolute_error: 0.0448 - mean_squared_error: 0.0100 - mean_absolute_percentage_error: 35.7471\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_absolute_error: 0.0428 - mean_squared_error: 0.0094 - mean_absolute_percentage_error: 31.7162\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0090 - mean_absolute_error: 0.0422 - mean_squared_error: 0.0090 - mean_absolute_percentage_error: 30.7643\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0103 - mean_absolute_error: 0.0463 - mean_squared_error: 0.0103 - mean_absolute_percentage_error: 33.3405\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0092 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0092 - mean_absolute_percentage_error: 29.7032\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0090 - mean_absolute_error: 0.0418 - mean_squared_error: 0.0090 - mean_absolute_percentage_error: 31.2121\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0088 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0088 - mean_absolute_percentage_error: 35.3469\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0083 - mean_absolute_error: 0.0404 - mean_squared_error: 0.0083 - mean_absolute_percentage_error: 31.4447\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0084 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0084 - mean_absolute_percentage_error: 28.3214   \n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_absolute_error: 0.0395 - mean_squared_error: 0.0082 - mean_absolute_percentage_error: 28.3595\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0081 - mean_absolute_error: 0.0405 - mean_squared_error: 0.0081 - mean_absolute_percentage_error: 29.9531\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0088 - mean_absolute_percentage_error: 31.6869\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0084 - mean_absolute_error: 0.0393 - mean_squared_error: 0.0084 - mean_absolute_percentage_error: 29.3192\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0081 - mean_absolute_error: 0.0404 - mean_squared_error: 0.0081 - mean_absolute_percentage_error: 30.3628\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0086 - mean_absolute_error: 0.0405 - mean_squared_error: 0.0086 - mean_absolute_percentage_error: 35.1059\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0083 - mean_absolute_error: 0.0396 - mean_squared_error: 0.0083 - mean_absolute_percentage_error: 29.2185\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0085 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0085 - mean_absolute_percentage_error: 35.0664\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0086 - mean_absolute_error: 0.0409 - mean_squared_error: 0.0086 - mean_absolute_percentage_error: 29.7803\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_absolute_error: 0.0389 - mean_squared_error: 0.0082 - mean_absolute_percentage_error: 31.6612\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0081 - mean_absolute_error: 0.0398 - mean_squared_error: 0.0081 - mean_absolute_percentage_error: 34.9155   \n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0086 - mean_absolute_error: 0.0402 - mean_squared_error: 0.0086 - mean_absolute_percentage_error: 28.9424\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0398 - mean_squared_error: 0.0080 - mean_absolute_percentage_error: 31.2316\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_absolute_error: 0.0400 - mean_squared_error: 0.0082 - mean_absolute_percentage_error: 31.3344\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0077 - mean_absolute_error: 0.0384 - mean_squared_error: 0.0077 - mean_absolute_percentage_error: 28.1093\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_absolute_error: 0.0361 - mean_squared_error: 0.0073 - mean_absolute_percentage_error: 28.3664\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0074 - mean_absolute_error: 0.0373 - mean_squared_error: 0.0074 - mean_absolute_percentage_error: 26.8171\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0075 - mean_absolute_error: 0.0377 - mean_squared_error: 0.0075 - mean_absolute_percentage_error: 26.4096\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_absolute_error: 0.0370 - mean_squared_error: 0.0071 - mean_absolute_percentage_error: 30.6869\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_absolute_error: 0.0360 - mean_squared_error: 0.0071 - mean_absolute_percentage_error: 28.7533\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0084 - mean_absolute_error: 0.0397 - mean_squared_error: 0.0084 - mean_absolute_percentage_error: 28.5358\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0078 - mean_absolute_error: 0.0379 - mean_squared_error: 0.0078 - mean_absolute_percentage_error: 26.1255\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0081 - mean_absolute_error: 0.0384 - mean_squared_error: 0.0081 - mean_absolute_percentage_error: 30.9510\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0069 - mean_absolute_error: 0.0363 - mean_squared_error: 0.0069 - mean_absolute_percentage_error: 29.1207\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_absolute_error: 0.0361 - mean_squared_error: 0.0070 - mean_absolute_percentage_error: 29.0128\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0064 - mean_absolute_error: 0.0350 - mean_squared_error: 0.0064 - mean_absolute_percentage_error: 26.7690\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0069 - mean_absolute_error: 0.0359 - mean_squared_error: 0.0069 - mean_absolute_percentage_error: 25.6651\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0087 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0087 - mean_absolute_percentage_error: 37.4483\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_absolute_error: 0.0370 - mean_squared_error: 0.0073 - mean_absolute_percentage_error: 28.1669\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0065 - mean_absolute_error: 0.0355 - mean_squared_error: 0.0065 - mean_absolute_percentage_error: 26.9240\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0062 - mean_absolute_error: 0.0338 - mean_squared_error: 0.0062 - mean_absolute_percentage_error: 28.3270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c37466dd8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.fit(\n",
    "    x_test,\n",
    "    y_test,\n",
    "epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='tanh')\n",
    "  ])\n",
    "\n",
    "big_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.MeanAbsolutePercentageError()],\n",
    "  loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "241/241 [==============================] - 1s 2ms/step - loss: 0.0951 - mean_absolute_error: 0.1889 - mean_squared_error: 0.0951 - mean_absolute_percentage_error: 72.2896\n",
      "Epoch 2/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0277 - mean_absolute_error: 0.0806 - mean_squared_error: 0.0277 - mean_absolute_percentage_error: 52.0642\n",
      "Epoch 3/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0260 - mean_absolute_error: 0.0750 - mean_squared_error: 0.0260 - mean_absolute_percentage_error: 51.8241\n",
      "Epoch 4/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0252 - mean_absolute_error: 0.0711 - mean_squared_error: 0.0252 - mean_absolute_percentage_error: 47.7683\n",
      "Epoch 5/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0246 - mean_absolute_error: 0.0699 - mean_squared_error: 0.0246 - mean_absolute_percentage_error: 53.8652\n",
      "Epoch 6/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0245 - mean_absolute_error: 0.0705 - mean_squared_error: 0.0245 - mean_absolute_percentage_error: 48.5598\n",
      "Epoch 7/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0233 - mean_absolute_error: 0.0658 - mean_squared_error: 0.0233 - mean_absolute_percentage_error: 46.8489\n",
      "Epoch 8/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0229 - mean_absolute_error: 0.0660 - mean_squared_error: 0.0229 - mean_absolute_percentage_error: 45.3624\n",
      "Epoch 9/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_absolute_error: 0.0646 - mean_squared_error: 0.0227 - mean_absolute_percentage_error: 42.8836\n",
      "Epoch 10/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0224 - mean_absolute_error: 0.0645 - mean_squared_error: 0.0224 - mean_absolute_percentage_error: 42.9553\n",
      "Epoch 11/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0218 - mean_absolute_error: 0.0636 - mean_squared_error: 0.0218 - mean_absolute_percentage_error: 42.6057\n",
      "Epoch 12/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_absolute_error: 0.0624 - mean_squared_error: 0.0214 - mean_absolute_percentage_error: 42.8844\n",
      "Epoch 13/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0214 - mean_absolute_error: 0.0617 - mean_squared_error: 0.0214 - mean_absolute_percentage_error: 43.3791\n",
      "Epoch 14/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0209 - mean_absolute_error: 0.0619 - mean_squared_error: 0.0209 - mean_absolute_percentage_error: 43.2911\n",
      "Epoch 15/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0209 - mean_absolute_error: 0.0614 - mean_squared_error: 0.0209 - mean_absolute_percentage_error: 44.1746\n",
      "Epoch 16/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0201 - mean_absolute_error: 0.0591 - mean_squared_error: 0.0201 - mean_absolute_percentage_error: 43.5406\n",
      "Epoch 17/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0202 - mean_absolute_error: 0.0589 - mean_squared_error: 0.0202 - mean_absolute_percentage_error: 40.5545\n",
      "Epoch 18/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0198 - mean_absolute_error: 0.0586 - mean_squared_error: 0.0198 - mean_absolute_percentage_error: 41.9031\n",
      "Epoch 19/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0195 - mean_absolute_error: 0.0571 - mean_squared_error: 0.0195 - mean_absolute_percentage_error: 41.8641\n",
      "Epoch 20/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0197 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0197 - mean_absolute_percentage_error: 46.3552\n",
      "Epoch 21/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0194 - mean_absolute_error: 0.0578 - mean_squared_error: 0.0194 - mean_absolute_percentage_error: 41.1102\n",
      "Epoch 22/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.0575 - mean_squared_error: 0.0189 - mean_absolute_percentage_error: 40.4356\n",
      "Epoch 23/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0188 - mean_absolute_error: 0.0565 - mean_squared_error: 0.0188 - mean_absolute_percentage_error: 38.7082\n",
      "Epoch 24/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.0554 - mean_squared_error: 0.0185 - mean_absolute_percentage_error: 43.3784\n",
      "Epoch 25/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0557 - mean_squared_error: 0.0183 - mean_absolute_percentage_error: 44.1399\n",
      "Epoch 26/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0183 - mean_absolute_error: 0.0555 - mean_squared_error: 0.0183 - mean_absolute_percentage_error: 41.4841\n",
      "Epoch 27/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0180 - mean_absolute_error: 0.0560 - mean_squared_error: 0.0180 - mean_absolute_percentage_error: 43.2859\n",
      "Epoch 28/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0179 - mean_absolute_error: 0.0556 - mean_squared_error: 0.0179 - mean_absolute_percentage_error: 41.5898\n",
      "Epoch 29/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0177 - mean_absolute_error: 0.0547 - mean_squared_error: 0.0177 - mean_absolute_percentage_error: 39.7648\n",
      "Epoch 30/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0176 - mean_absolute_error: 0.0548 - mean_squared_error: 0.0176 - mean_absolute_percentage_error: 41.4321\n",
      "Epoch 31/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0173 - mean_absolute_error: 0.0537 - mean_squared_error: 0.0173 - mean_absolute_percentage_error: 41.2839\n",
      "Epoch 32/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0171 - mean_absolute_error: 0.0541 - mean_squared_error: 0.0171 - mean_absolute_percentage_error: 42.5421\n",
      "Epoch 33/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0168 - mean_absolute_error: 0.0524 - mean_squared_error: 0.0168 - mean_absolute_percentage_error: 38.9349\n",
      "Epoch 34/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0170 - mean_absolute_error: 0.0534 - mean_squared_error: 0.0170 - mean_absolute_percentage_error: 41.2061\n",
      "Epoch 35/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0162 - mean_absolute_error: 0.0509 - mean_squared_error: 0.0162 - mean_absolute_percentage_error: 37.3215\n",
      "Epoch 36/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0164 - mean_absolute_error: 0.0525 - mean_squared_error: 0.0164 - mean_absolute_percentage_error: 40.1481\n",
      "Epoch 37/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0172 - mean_absolute_error: 0.0534 - mean_squared_error: 0.0172 - mean_absolute_percentage_error: 40.0041\n",
      "Epoch 38/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0160 - mean_absolute_error: 0.0521 - mean_squared_error: 0.0160 - mean_absolute_percentage_error: 43.7393\n",
      "Epoch 39/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0161 - mean_absolute_error: 0.0517 - mean_squared_error: 0.0161 - mean_absolute_percentage_error: 37.0402\n",
      "Epoch 40/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0159 - mean_absolute_error: 0.0508 - mean_squared_error: 0.0159 - mean_absolute_percentage_error: 42.1802\n",
      "Epoch 41/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_absolute_error: 0.0504 - mean_squared_error: 0.0153 - mean_absolute_percentage_error: 39.0031\n",
      "Epoch 42/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0155 - mean_absolute_error: 0.0507 - mean_squared_error: 0.0155 - mean_absolute_percentage_error: 38.2687\n",
      "Epoch 43/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_absolute_error: 0.0507 - mean_squared_error: 0.0153 - mean_absolute_percentage_error: 39.6606\n",
      "Epoch 44/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0151 - mean_absolute_error: 0.0495 - mean_squared_error: 0.0151 - mean_absolute_percentage_error: 35.2718\n",
      "Epoch 45/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0151 - mean_absolute_error: 0.0503 - mean_squared_error: 0.0151 - mean_absolute_percentage_error: 38.7164\n",
      "Epoch 46/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0151 - mean_absolute_error: 0.0501 - mean_squared_error: 0.0151 - mean_absolute_percentage_error: 37.3826\n",
      "Epoch 47/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0146 - mean_absolute_error: 0.0488 - mean_squared_error: 0.0146 - mean_absolute_percentage_error: 35.0359\n",
      "Epoch 48/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0143 - mean_absolute_error: 0.0480 - mean_squared_error: 0.0143 - mean_absolute_percentage_error: 34.5604\n",
      "Epoch 49/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0148 - mean_absolute_error: 0.0495 - mean_squared_error: 0.0148 - mean_absolute_percentage_error: 38.0862\n",
      "Epoch 50/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0150 - mean_absolute_error: 0.0499 - mean_squared_error: 0.0150 - mean_absolute_percentage_error: 40.1428\n",
      "Epoch 51/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0141 - mean_absolute_error: 0.0486 - mean_squared_error: 0.0141 - mean_absolute_percentage_error: 39.7829\n",
      "Epoch 52/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0138 - mean_absolute_error: 0.0475 - mean_squared_error: 0.0138 - mean_absolute_percentage_error: 32.0479\n",
      "Epoch 53/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0141 - mean_absolute_error: 0.0475 - mean_squared_error: 0.0141 - mean_absolute_percentage_error: 36.9181\n",
      "Epoch 54/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0140 - mean_absolute_error: 0.0477 - mean_squared_error: 0.0140 - mean_absolute_percentage_error: 43.3500\n",
      "Epoch 55/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0140 - mean_absolute_error: 0.0475 - mean_squared_error: 0.0140 - mean_absolute_percentage_error: 38.1328\n",
      "Epoch 56/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0140 - mean_absolute_error: 0.0484 - mean_squared_error: 0.0140 - mean_absolute_percentage_error: 40.2488\n",
      "Epoch 57/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0136 - mean_absolute_error: 0.0472 - mean_squared_error: 0.0136 - mean_absolute_percentage_error: 32.1150\n",
      "Epoch 58/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0139 - mean_absolute_error: 0.0478 - mean_squared_error: 0.0139 - mean_absolute_percentage_error: 34.7823\n",
      "Epoch 59/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0133 - mean_absolute_error: 0.0461 - mean_squared_error: 0.0133 - mean_absolute_percentage_error: 40.7369\n",
      "Epoch 60/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0132 - mean_absolute_error: 0.0462 - mean_squared_error: 0.0132 - mean_absolute_percentage_error: 37.3604\n",
      "Epoch 61/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0129 - mean_absolute_error: 0.0451 - mean_squared_error: 0.0129 - mean_absolute_percentage_error: 32.3190\n",
      "Epoch 62/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0131 - mean_absolute_error: 0.0454 - mean_squared_error: 0.0131 - mean_absolute_percentage_error: 37.6289\n",
      "Epoch 63/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0136 - mean_absolute_error: 0.0461 - mean_squared_error: 0.0136 - mean_absolute_percentage_error: 34.3039\n",
      "Epoch 64/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0125 - mean_absolute_error: 0.0441 - mean_squared_error: 0.0125 - mean_absolute_percentage_error: 41.2639\n",
      "Epoch 65/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_absolute_error: 0.0448 - mean_squared_error: 0.0126 - mean_absolute_percentage_error: 40.5014\n",
      "Epoch 66/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0133 - mean_absolute_error: 0.0463 - mean_squared_error: 0.0133 - mean_absolute_percentage_error: 39.3770\n",
      "Epoch 67/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_absolute_error: 0.0458 - mean_squared_error: 0.0126 - mean_absolute_percentage_error: 39.3171\n",
      "Epoch 68/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_absolute_error: 0.0446 - mean_squared_error: 0.0124 - mean_absolute_percentage_error: 38.5112\n",
      "Epoch 69/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_absolute_error: 0.0449 - mean_squared_error: 0.0126 - mean_absolute_percentage_error: 36.2488\n",
      "Epoch 70/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0126 - mean_absolute_error: 0.0451 - mean_squared_error: 0.0126 - mean_absolute_percentage_error: 32.1311\n",
      "Epoch 71/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0125 - mean_absolute_error: 0.0444 - mean_squared_error: 0.0125 - mean_absolute_percentage_error: 37.4114\n",
      "Epoch 72/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0122 - mean_absolute_error: 0.0442 - mean_squared_error: 0.0122 - mean_absolute_percentage_error: 35.6312\n",
      "Epoch 73/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0127 - mean_absolute_error: 0.0446 - mean_squared_error: 0.0127 - mean_absolute_percentage_error: 35.8290\n",
      "Epoch 74/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_absolute_error: 0.0439 - mean_squared_error: 0.0124 - mean_absolute_percentage_error: 32.8662\n",
      "Epoch 75/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0125 - mean_absolute_error: 0.0445 - mean_squared_error: 0.0125 - mean_absolute_percentage_error: 39.9870\n",
      "Epoch 76/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0120 - mean_absolute_error: 0.0436 - mean_squared_error: 0.0120 - mean_absolute_percentage_error: 33.6872: 0s - loss: 0.0120 - mean_absolute_error: 0.0388 - mean_squared_error: 0.0120 - mean_absolute_percentage_erro\n",
      "Epoch 77/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0118 - mean_absolute_error: 0.0433 - mean_squared_error: 0.0118 - mean_absolute_percentage_error: 30.4822\n",
      "Epoch 78/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0119 - mean_absolute_error: 0.0425 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 31.4670\n",
      "Epoch 79/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0123 - mean_absolute_error: 0.0438 - mean_squared_error: 0.0123 - mean_absolute_percentage_error: 40.8868\n",
      "Epoch 80/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_absolute_error: 0.0427 - mean_squared_error: 0.0114 - mean_absolute_percentage_error: 31.7517\n",
      "Epoch 81/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0438 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 37.3742\n",
      "Epoch 82/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0114 - mean_absolute_error: 0.0421 - mean_squared_error: 0.0114 - mean_absolute_percentage_error: 35.5787\n",
      "Epoch 83/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0117 - mean_absolute_error: 0.0425 - mean_squared_error: 0.0117 - mean_absolute_percentage_error: 32.1786\n",
      "Epoch 84/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0114 - mean_absolute_error: 0.0430 - mean_squared_error: 0.0114 - mean_absolute_percentage_error: 36.4595\n",
      "Epoch 85/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0116 - mean_absolute_error: 0.0424 - mean_squared_error: 0.0116 - mean_absolute_percentage_error: 30.9119\n",
      "Epoch 86/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_absolute_error: 0.0420 - mean_squared_error: 0.0111 - mean_absolute_percentage_error: 34.4649\n",
      "Epoch 87/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0430 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 36.3790\n",
      "Epoch 88/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0124 - mean_absolute_error: 0.0443 - mean_squared_error: 0.0124 - mean_absolute_percentage_error: 32.8252\n",
      "Epoch 89/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0116 - mean_absolute_error: 0.0421 - mean_squared_error: 0.0116 - mean_absolute_percentage_error: 34.8565\n",
      "Epoch 90/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0109 - mean_absolute_percentage_error: 31.5154\n",
      "Epoch 91/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0105 - mean_absolute_percentage_error: 34.8576\n",
      "Epoch 92/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_absolute_error: 0.0412 - mean_squared_error: 0.0109 - mean_absolute_percentage_error: 34.4225\n",
      "Epoch 93/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0110 - mean_absolute_error: 0.0413 - mean_squared_error: 0.0110 - mean_absolute_percentage_error: 34.4704\n",
      "Epoch 94/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0431 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 31.3152\n",
      "Epoch 95/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0109 - mean_absolute_percentage_error: 35.6992\n",
      "Epoch 96/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_absolute_error: 0.0404 - mean_squared_error: 0.0106 - mean_absolute_percentage_error: 33.7779\n",
      "Epoch 97/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0111 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0111 - mean_absolute_percentage_error: 31.3152\n",
      "Epoch 98/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0107 - mean_absolute_error: 0.0400 - mean_squared_error: 0.0107 - mean_absolute_percentage_error: 29.1728\n",
      "Epoch 99/100\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_absolute_error: 0.0409 - mean_squared_error: 0.0108 - mean_absolute_percentage_error: 29.4036\n",
      "Epoch 100/100\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 0.0104 - mean_absolute_error: 0.0398 - mean_squared_error: 0.0104 - mean_absolute_percentage_error: 29.9652\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c362c3860>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0311 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0311 - mean_absolute_percentage_error: 57.3595\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0190 - mean_absolute_error: 0.0625 - mean_squared_error: 0.0190 - mean_absolute_percentage_error: 36.0688\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0165 - mean_absolute_error: 0.0603 - mean_squared_error: 0.0165 - mean_absolute_percentage_error: 34.9843\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0142 - mean_absolute_error: 0.0533 - mean_squared_error: 0.0142 - mean_absolute_percentage_error: 33.1470\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0133 - mean_absolute_error: 0.0521 - mean_squared_error: 0.0133 - mean_absolute_percentage_error: 39.0304\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0119 - mean_absolute_error: 0.0490 - mean_squared_error: 0.0119 - mean_absolute_percentage_error: 36.0513\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_absolute_error: 0.0496 - mean_squared_error: 0.0121 - mean_absolute_percentage_error: 33.3697\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0108 - mean_absolute_error: 0.0467 - mean_squared_error: 0.0108 - mean_absolute_percentage_error: 31.5553\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0115 - mean_absolute_error: 0.0500 - mean_squared_error: 0.0115 - mean_absolute_percentage_error: 35.7237\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0105 - mean_absolute_error: 0.0464 - mean_squared_error: 0.0105 - mean_absolute_percentage_error: 28.9113\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0099 - mean_absolute_error: 0.0435 - mean_squared_error: 0.0099 - mean_absolute_percentage_error: 28.2518\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0102 - mean_absolute_error: 0.0441 - mean_squared_error: 0.0102 - mean_absolute_percentage_error: 34.8943\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0089 - mean_absolute_error: 0.0428 - mean_squared_error: 0.0089 - mean_absolute_percentage_error: 26.7153\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0092 - mean_absolute_error: 0.0425 - mean_squared_error: 0.0092 - mean_absolute_percentage_error: 30.3834\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0414 - mean_squared_error: 0.0088 - mean_absolute_percentage_error: 31.6999\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0093 - mean_absolute_error: 0.0423 - mean_squared_error: 0.0093 - mean_absolute_percentage_error: 34.3868\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0103 - mean_absolute_error: 0.0460 - mean_squared_error: 0.0103 - mean_absolute_percentage_error: 36.3031\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0096 - mean_absolute_error: 0.0455 - mean_squared_error: 0.0096 - mean_absolute_percentage_error: 35.4544\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0078 - mean_absolute_error: 0.0391 - mean_squared_error: 0.0078 - mean_absolute_percentage_error: 30.2724\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0077 - mean_absolute_error: 0.0379 - mean_squared_error: 0.0077 - mean_absolute_percentage_error: 30.2210\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0070 - mean_absolute_error: 0.0369 - mean_squared_error: 0.0070 - mean_absolute_percentage_error: 31.8799\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_absolute_error: 0.0372 - mean_squared_error: 0.0071 - mean_absolute_percentage_error: 28.9985\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0075 - mean_absolute_error: 0.0374 - mean_squared_error: 0.0075 - mean_absolute_percentage_error: 28.6296\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0066 - mean_absolute_error: 0.0356 - mean_squared_error: 0.0066 - mean_absolute_percentage_error: 26.6486\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0067 - mean_absolute_error: 0.0355 - mean_squared_error: 0.0067 - mean_absolute_percentage_error: 27.1794\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0065 - mean_absolute_error: 0.0354 - mean_squared_error: 0.0065 - mean_absolute_percentage_error: 28.4002\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0067 - mean_absolute_error: 0.0358 - mean_squared_error: 0.0067 - mean_absolute_percentage_error: 30.4114\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0061 - mean_absolute_error: 0.0341 - mean_squared_error: 0.0061 - mean_absolute_percentage_error: 30.1436\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_absolute_error: 0.0383 - mean_squared_error: 0.0072 - mean_absolute_percentage_error: 31.8190\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0077 - mean_absolute_error: 0.0390 - mean_squared_error: 0.0077 - mean_absolute_percentage_error: 36.6091\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0067 - mean_absolute_error: 0.0361 - mean_squared_error: 0.0067 - mean_absolute_percentage_error: 33.7852\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0062 - mean_absolute_error: 0.0339 - mean_squared_error: 0.0062 - mean_absolute_percentage_error: 30.1139\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0063 - mean_absolute_error: 0.0355 - mean_squared_error: 0.0063 - mean_absolute_percentage_error: 31.8350\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0061 - mean_absolute_error: 0.0335 - mean_squared_error: 0.0061 - mean_absolute_percentage_error: 28.7909\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0328 - mean_squared_error: 0.0056 - mean_absolute_percentage_error: 27.6857\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0053 - mean_absolute_error: 0.0318 - mean_squared_error: 0.0053 - mean_absolute_percentage_error: 31.2459\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0056 - mean_absolute_error: 0.0322 - mean_squared_error: 0.0056 - mean_absolute_percentage_error: 32.5810\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0052 - mean_absolute_error: 0.0317 - mean_squared_error: 0.0052 - mean_absolute_percentage_error: 28.4614\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0052 - mean_absolute_error: 0.0319 - mean_squared_error: 0.0052 - mean_absolute_percentage_error: 25.6721\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0307 - mean_squared_error: 0.0049 - mean_absolute_percentage_error: 25.8894\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0047 - mean_absolute_error: 0.0300 - mean_squared_error: 0.0047 - mean_absolute_percentage_error: 24.7248\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0052 - mean_absolute_error: 0.0323 - mean_squared_error: 0.0052 - mean_absolute_percentage_error: 25.9238\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0050 - mean_absolute_error: 0.0318 - mean_squared_error: 0.0050 - mean_absolute_percentage_error: 34.3416\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0042 - mean_absolute_error: 0.0285 - mean_squared_error: 0.0042 - mean_absolute_percentage_error: 24.9933\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0040 - mean_absolute_error: 0.0274 - mean_squared_error: 0.0040 - mean_absolute_percentage_error: 24.4208\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0042 - mean_absolute_error: 0.0283 - mean_squared_error: 0.0042 - mean_absolute_percentage_error: 26.9778\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0039 - mean_absolute_error: 0.0277 - mean_squared_error: 0.0039 - mean_absolute_percentage_error: 27.8787\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0037 - mean_absolute_error: 0.0271 - mean_squared_error: 0.0037 - mean_absolute_percentage_error: 22.5260\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0037 - mean_absolute_error: 0.0276 - mean_squared_error: 0.0037 - mean_absolute_percentage_error: 24.3318\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0040 - mean_absolute_error: 0.0274 - mean_squared_error: 0.0040 - mean_absolute_percentage_error: 25.7502\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0036 - mean_absolute_error: 0.0277 - mean_squared_error: 0.0036 - mean_absolute_percentage_error: 24.3231\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_absolute_error: 0.0261 - mean_squared_error: 0.0035 - mean_absolute_percentage_error: 22.8972\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0036 - mean_absolute_error: 0.0270 - mean_squared_error: 0.0036 - mean_absolute_percentage_error: 26.6779\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0035 - mean_absolute_error: 0.0268 - mean_squared_error: 0.0035 - mean_absolute_percentage_error: 24.4067\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0035 - mean_absolute_error: 0.0273 - mean_squared_error: 0.0035 - mean_absolute_percentage_error: 23.5847\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0033 - mean_absolute_error: 0.0250 - mean_squared_error: 0.0033 - mean_absolute_percentage_error: 21.2552\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0030 - mean_absolute_error: 0.0241 - mean_squared_error: 0.0030 - mean_absolute_percentage_error: 22.2690\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0235 - mean_squared_error: 0.0029 - mean_absolute_percentage_error: 22.3481\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0029 - mean_absolute_error: 0.0234 - mean_squared_error: 0.0029 - mean_absolute_percentage_error: 23.9718\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0238 - mean_squared_error: 0.0029 - mean_absolute_percentage_error: 22.3964\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0027 - mean_absolute_error: 0.0231 - mean_squared_error: 0.0027 - mean_absolute_percentage_error: 21.2911\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0242 - mean_squared_error: 0.0028 - mean_absolute_percentage_error: 23.0351\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0028 - mean_absolute_error: 0.0237 - mean_squared_error: 0.0028 - mean_absolute_percentage_error: 21.6592\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0029 - mean_absolute_error: 0.0235 - mean_squared_error: 0.0029 - mean_absolute_percentage_error: 24.4985\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0221 - mean_squared_error: 0.0025 - mean_absolute_percentage_error: 20.9423\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0032 - mean_absolute_error: 0.0251 - mean_squared_error: 0.0032 - mean_absolute_percentage_error: 27.3138   \n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0043 - mean_absolute_error: 0.0295 - mean_squared_error: 0.0043 - mean_absolute_percentage_error: 24.0553\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0049 - mean_absolute_error: 0.0311 - mean_squared_error: 0.0049 - mean_absolute_percentage_error: 30.6453\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0040 - mean_absolute_error: 0.0281 - mean_squared_error: 0.0040 - mean_absolute_percentage_error: 28.0100\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.0039 - mean_absolute_error: 0.0278 - mean_squared_error: 0.0039 - mean_absolute_percentage_error: 26.0554\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0037 - mean_absolute_error: 0.0273 - mean_squared_error: 0.0037 - mean_absolute_percentage_error: 26.2134\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0034 - mean_absolute_error: 0.0263 - mean_squared_error: 0.0034 - mean_absolute_percentage_error: 22.5671   \n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0028 - mean_absolute_error: 0.0242 - mean_squared_error: 0.0028 - mean_absolute_percentage_error: 22.1454\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0027 - mean_absolute_error: 0.0227 - mean_squared_error: 0.0027 - mean_absolute_percentage_error: 22.4801\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0224 - mean_squared_error: 0.0026 - mean_absolute_percentage_error: 22.1372\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0219 - mean_squared_error: 0.0025 - mean_absolute_percentage_error: 19.8645\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0024 - mean_absolute_error: 0.0217 - mean_squared_error: 0.0024 - mean_absolute_percentage_error: 23.8031   \n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0206 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 19.6257\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0202 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 20.4645   \n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0205 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 21.5005\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0024 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0024 - mean_absolute_percentage_error: 22.2251\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0225 - mean_squared_error: 0.0025 - mean_absolute_percentage_error: 26.1693\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0206 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 20.8676\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0021 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0021 - mean_absolute_percentage_error: 17.3959\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0021 - mean_absolute_error: 0.0197 - mean_squared_error: 0.0021 - mean_absolute_percentage_error: 23.8625\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0021 - mean_absolute_error: 0.0205 - mean_squared_error: 0.0021 - mean_absolute_percentage_error: 18.8534   \n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0208 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 20.2771\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0023 - mean_absolute_error: 0.0213 - mean_squared_error: 0.0023 - mean_absolute_percentage_error: 22.4540\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0018 - mean_absolute_error: 0.0177 - mean_squared_error: 0.0018 - mean_absolute_percentage_error: 18.8420   \n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0023 - mean_absolute_error: 0.0215 - mean_squared_error: 0.0023 - mean_absolute_percentage_error: 18.2202\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.0022 - mean_absolute_error: 0.0212 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 16.8970\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0023 - mean_absolute_error: 0.0224 - mean_squared_error: 0.0023 - mean_absolute_percentage_error: 21.3886\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0025 - mean_absolute_error: 0.0219 - mean_squared_error: 0.0025 - mean_absolute_percentage_error: 20.7334\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0020 - mean_absolute_error: 0.0203 - mean_squared_error: 0.0020 - mean_absolute_percentage_error: 19.3073\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0020 - mean_absolute_error: 0.0196 - mean_squared_error: 0.0020 - mean_absolute_percentage_error: 16.8381\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0017 - mean_absolute_error: 0.0180 - mean_squared_error: 0.0017 - mean_absolute_percentage_error: 17.8957\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0019 - mean_absolute_error: 0.0195 - mean_squared_error: 0.0019 - mean_absolute_percentage_error: 22.0482\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0019 - mean_absolute_error: 0.0193 - mean_squared_error: 0.0019 - mean_absolute_percentage_error: 19.5814\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0026 - mean_absolute_error: 0.0227 - mean_squared_error: 0.0026 - mean_absolute_percentage_error: 27.7429\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.0022 - mean_absolute_error: 0.0209 - mean_squared_error: 0.0022 - mean_absolute_percentage_error: 20.7309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c37725fd0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_model.fit(\n",
    "    x_test,\n",
    "    y_test,\n",
    "epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(16, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(8, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(4, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    tf.keras.layers.Dense(1,activation='tanh')\n",
    "  ])\n",
    "\n",
    "reg_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "  metrics=[tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.MeanAbsolutePercentageError()],\n",
    "  loss='mse')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4e9cda46bb2d9d7fe6ecdff0f8336a934348bf06cb492f2f42f60739b3403b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
