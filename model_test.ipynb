{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "pd.set_option(\"max_columns\",None)\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "#from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.layers import Dense\n",
    "#from tensorflow.keras.activations import relu,linear\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from matplotlib import units\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,make_scorer,r2_score\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api  as sm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge, SGDRegressor,LinearRegression,RidgeCV\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder,StandardScaler,RobustScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import ExtraTreeRegressor,DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pprint\n",
    "\n",
    "pd.set_option('max_columns', 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.ExcelFile('C:/Users/halil/Desktop/soalr_data.xlsx').parse('sheet 1')\n",
    "weather_raw = pd.read_excel('C:/Users/halil/Desktop/soalr_data.xlsx',sheet_name=\"weather\")\n",
    "guneko_raw = pd.read_excel('C:/Users/halil/Desktop/soalr_data.xlsx',sheet_name=\"1000255-GUNEKO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guneko_production = guneko_raw[[\"Date\",\"Production\"]]\n",
    "guneko_gti = guneko_raw[[\"Date.1\",\"GTI\"]]\n",
    "\n",
    "\n",
    "weather_guneko = weather_raw.loc[weather_raw.name ==1000255]\n",
    "dataset1 = pd.merge(guneko_production,weather_guneko,left_on=\"Date\",right_on=\"date\")\n",
    "#dataset1 = ali.drop([\"name\",\"date\",\"lat\",\"lon\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y  = dataset1[\"Production\"]\n",
    "x = dataset1.drop(\"Production\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=0.8,shuffle=False,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(dataset):\n",
    "    veli = dataset.copy()\n",
    "    dataset= dataset.set_index([\"Date\"])\n",
    "    year = pd.DataFrame(data=pd.get_dummies(dataset.index.year,prefix=\"year\"))\n",
    "    month = pd.DataFrame(data=pd.get_dummies(dataset.index.month, prefix=\"month\"))\n",
    "    day = pd.DataFrame(data=pd.get_dummies(dataset.index.day,prefix=\"day\"))\n",
    "    hour = pd.DataFrame(data=pd.get_dummies(dataset.index.hour,prefix=\"hour\"))\n",
    "    frames = [year,month,day,hour]\n",
    "\n",
    "    final = veli.join(frames)\n",
    "    final = final.drop([\"Date\",\"name\",\"date\",\"lat\",\"lon\"],axis=1)\n",
    "\n",
    "    return final\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df,column_list):\n",
    "    for col in column_list:\n",
    "        feature_range = (-1,1)\n",
    "        min_max_scaler = MinMaxScaler(feature_range=feature_range)\n",
    "\n",
    "        df[col] = min_max_scaler.fit_transform(df[col].values.reshape(-1,1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = onehot(x_train)\n",
    "x_test = onehot(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train,x_train.columns[0:10])\n",
    "x_test = normalize(x_test,x_test.columns[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "y_train = min_max_scaler.fit_transform(y_train.values.reshape(-1,1))\n",
    "y_test = min_max_scaler.fit_transform(y_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       -1.000000\n",
       "1       -1.000000\n",
       "2       -1.000000\n",
       "3       -1.000000\n",
       "4       -1.000000\n",
       "           ...   \n",
       "15223    0.647648\n",
       "15224    0.725726\n",
       "15225    0.673674\n",
       "15226    0.501502\n",
       "15227    0.191191\n",
       "Name: production, Length: 15228, dtype: float64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(y_train, columns = ['production'])\n",
    "\n",
    "aly = df[\"production\"]\n",
    "aly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(len(normalized) * 0.8)\n",
    "train_dataset = normalized[:size]\n",
    "test_dataset = normalized[size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: -1865878302575291793408.000000 (+/- 5597634907725874855936.000000)\n",
      "XGB: 0.881599 (+/- 0.061454)\n",
      "KNN: 0.854822 (+/- 0.094151)\n",
      "DTR: 0.800709 (+/- 0.107840)\n",
      "RFRegressor: 0.881784 (+/- 0.071600)\n",
      "GBRegressor: 0.887422 (+/- 0.060893)\n",
      "MLP: 0.797446 (+/- 0.096995)\n",
      "EXT Regressor: 0.809056 (+/- 0.108848)\n",
      "SV Regressor: 0.873120 (+/- 0.077976)\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfs = []\n",
    "\n",
    "seed = 3\n",
    "\n",
    "clfs.append((\"LinearRegression\", Pipeline([(\"Scaler\", RobustScaler()), (\"LogReg\", LinearRegression())])))\n",
    "\n",
    "clfs.append((\"XGB\", Pipeline([(\"Scaler\", RobustScaler()), (\"XGB\", XGBRegressor())]))) \n",
    "\n",
    "clfs.append((\"KNN\", Pipeline([(\"Scaler\", RobustScaler()),(\"KNN\", KNeighborsRegressor())]))) \n",
    "\n",
    "clfs.append((\"DTR\", Pipeline([(\"Scaler\", RobustScaler()), (\"DecisionTrees\", DecisionTreeRegressor())]))) \n",
    "\n",
    "clfs.append((\"RFRegressor\", Pipeline([(\"Scaler\", RobustScaler()), (\"RandomForest\", RandomForestRegressor())]))) \n",
    "\n",
    "clfs.append((\"GBRegressor\", Pipeline([(\"Scaler\", RobustScaler()), (\"GradientBoosting\", GradientBoostingRegressor())]))) \n",
    "\n",
    "clfs.append((\"MLP\", Pipeline([(\"Scaler\", RobustScaler()),(\"MLP Regressor\", MLPRegressor())])))\n",
    "\n",
    "clfs.append((\"EXT Regressor\",Pipeline([(\"Scaler\", RobustScaler()),(\"ExtraTrees\", ExtraTreeRegressor())])))\n",
    "\n",
    "clfs.append((\"SV Regressor\", Pipeline([(\"Scaler\", RobustScaler()),(\"ExtraTrees\", SVR())])))\n",
    "\n",
    "scoring = 'r2'\n",
    "n_folds = 10\n",
    "msgs = []\n",
    "results, names  = [], [] \n",
    "\n",
    "for name, model  in clfs:\n",
    "    kfold = KFold(n_splits=n_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, x_train, y_train,cv=kfold, scoring=scoring, n_jobs=-1)    \n",
    "    names.append(name)\n",
    "    results.append(cv_results)    \n",
    "    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msgs.append(msg)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clfs = []\n",
    "seed = 3\n",
    "\n",
    "clfs.append((\"LinearRegression\", Pipeline([(\"LogReg\", LinearRegression())])))\n",
    "\n",
    "clfs.append((\"XGB\", Pipeline([(\"XGB\", XGBRegressor())]))) \n",
    "\n",
    "clfs.append((\"KNN\", Pipeline([(\"KNN\", KNeighborsRegressor())]))) \n",
    "\n",
    "clfs.append((\"DTR\", Pipeline([(\"DecisionTrees\", DecisionTreeRegressor())]))) \n",
    "\n",
    "clfs.append((\"RFRegressor\", Pipeline([(\"RandomForest\", RandomForestRegressor())]))) \n",
    "\n",
    "clfs.append((\"GBRegressor\", Pipeline([(\"GradientBoosting\", GradientBoostingRegressor())]))) \n",
    "\n",
    "clfs.append((\"MLP\", Pipeline([(\"MLP Regressor\", MLPRegressor())])))\n",
    "\n",
    "clfs.append((\"EXT Regressor\",Pipeline([(\"ExtraTrees\", ExtraTreeRegressor())])))\n",
    "\n",
    "clfs.append((\"SV Regressor\", Pipeline([(\"ExtraTrees\", SVR())])))\n",
    "\n",
    "scoring = 'mae'\n",
    "n_folds = 10\n",
    "msgs = []\n",
    "results, names  = [], [] \n",
    "\n",
    "for name, model  in clfs:\n",
    "    kfold = KFold(n_splits=n_folds, random_state=None)\n",
    "    cv_results = cross_val_score(model, x_train, y_train, cv=kfold, scoring=scoring, n_jobs=-1)    \n",
    "    names.append(name)\n",
    "    results.append(cv_results)    \n",
    "    msg = \"%s: %f (+/- %f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    msgs.append(msg)\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4e9cda46bb2d9d7fe6ecdff0f8336a934348bf06cb492f2f42f60739b3403b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
